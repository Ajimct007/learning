{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBehvqZ8znsy"
      },
      "source": [
        "# Using optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCdIqY0tKbvS"
      },
      "source": [
        "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCJzXv0OK1Bs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f5eec1-7aa3-49b3-92f0-27317f725e3c"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean, std = (0.5,), (0.5,)\n",
        "\n",
        "# Create a transform and normalise data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)\n",
        "                              ])\n",
        "\n",
        "# Download FMNIST training dataset and load training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download FMNIST test dataset and load test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 14073948.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 281857.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 4989057.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 19244453.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZpZ12MrEDZI"
      },
      "source": [],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqMqFbIVrbFH"
      },
      "source": [
        "class FMNIST(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(784, 128)\n",
        "    self.fc2 = nn.Linear(128,64)\n",
        "    self.fc3 = nn.Linear(64,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0], -1)\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "\n",
        "    return x\n",
        "\n",
        "#model = FMNIST()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m68OeMRdEF0X"
      },
      "source": [],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c0QgxCF3fD-"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjBut_7lhAc8"
      },
      "source": [],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2ZAGFzFEQA_"
      },
      "source": [],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iPQek2nz2yu"
      },
      "source": [
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMnVwV-CERd_"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roihp-kN0Jw5"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01) # here lr is the learning rate\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvbHIyPSEUPh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtP3nCEQEUMH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwcPkxQwEfYX"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nf2WdmP5Gst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1df7c2d-22dc-492f-c3ef-914b68562006"
      },
      "source": [
        "# forward pass, calculate loss, backword pass\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Initial weights : ',model[0].weight)\n",
        "print('Initial weights gradient : ',model[0].weight.grad)\n",
        ""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights :  Parameter containing:\n",
            "tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
            "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
            "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
            "        ...,\n",
            "        [ 0.0018, -0.0295,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
            "        [-0.0233, -0.0220, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n",
            "        [ 0.0309,  0.0066,  0.0125,  ...,  0.0286,  0.0350, -0.0105]],\n",
            "       requires_grad=True)\n",
            "Initial weights gradient :  tensor([[-0.0030, -0.0030, -0.0030,  ..., -0.0030, -0.0030, -0.0030],\n",
            "        [ 0.0022,  0.0022,  0.0022,  ...,  0.0024,  0.0022,  0.0022],\n",
            "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
            "        ...,\n",
            "        [ 0.0014,  0.0014,  0.0014,  ...,  0.0014,  0.0014,  0.0014],\n",
            "        [ 0.0021,  0.0021,  0.0021,  ...,  0.0022,  0.0021,  0.0021],\n",
            "        [ 0.0038,  0.0038,  0.0038,  ...,  0.0038,  0.0038,  0.0038]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arwzAK-1EkEH"
      },
      "source": [
        "# Update the weights using step function of the optimizer\n",
        "optimizer.step()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD-u49yzEj6v"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuGKi_nq6P0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb99c61-2784-4716-f7fe-1b07e5e65aee"
      },
      "source": [
        "# after running the optimizer the weights are updated\n",
        "print('Initial weights : ',model[0].weight)\n",
        "print('Initial weights gradient : ',model[0].weight.grad)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights :  Parameter containing:\n",
            "tensor([[-0.0002,  0.0192, -0.0294,  ...,  0.0220,  0.0038,  0.0021],\n",
            "        [-0.0198, -0.0150, -0.0105,  ..., -0.0203, -0.0060, -0.0300],\n",
            "        [-0.0202,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
            "        ...,\n",
            "        [ 0.0018, -0.0296,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
            "        [-0.0233, -0.0221, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n",
            "        [ 0.0309,  0.0065,  0.0125,  ...,  0.0285,  0.0349, -0.0106]],\n",
            "       requires_grad=True)\n",
            "Initial weights gradient :  tensor([[-0.0030, -0.0030, -0.0030,  ..., -0.0030, -0.0030, -0.0030],\n",
            "        [ 0.0022,  0.0022,  0.0022,  ...,  0.0024,  0.0022,  0.0022],\n",
            "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
            "        ...,\n",
            "        [ 0.0014,  0.0014,  0.0014,  ...,  0.0014,  0.0014,  0.0014],\n",
            "        [ 0.0021,  0.0021,  0.0021,  ...,  0.0022,  0.0021,  0.0021],\n",
            "        [ 0.0038,  0.0038,  0.0038,  ...,  0.0038,  0.0038,  0.0038]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8oIy5SkEpDn"
      },
      "source": [
        "# we updated the weights and we dont want them to accumulated so zero them up\n",
        "optimizer.zero_grad()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnfpzGigEpAr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EniqxHDwDa8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978ff806-88ff-410a-9eb2-d06fde07b2e7"
      },
      "source": [
        "print('Initial weights : ',model[0].weight)\n",
        "print('Initial weights gradient : ',model[0].weight.grad)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights :  Parameter containing:\n",
            "tensor([[-0.0002,  0.0192, -0.0294,  ...,  0.0220,  0.0038,  0.0021],\n",
            "        [-0.0198, -0.0150, -0.0105,  ..., -0.0203, -0.0060, -0.0300],\n",
            "        [-0.0202,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
            "        ...,\n",
            "        [ 0.0018, -0.0296,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
            "        [-0.0233, -0.0221, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n",
            "        [ 0.0309,  0.0065,  0.0125,  ...,  0.0285,  0.0349, -0.0106]],\n",
            "       requires_grad=True)\n",
            "Initial weights gradient :  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DViAViGEwyr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGZhQE3tDcqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8c3ad0-cd2b-42b9-ac57-18e6b7e47b32"
      },
      "source": [
        "model = FMNIST()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    cum_loss = 0\n",
        "    batch_num = 0\n",
        "    for batch_num, (images, labels) in enumerate(trainloader, 1):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cum_loss += loss.item()\n",
        "        print(f'Batch : {batch_num}, Loss : {loss.item()}')\n",
        "\n",
        "    print(f\"Training loss: {cum_loss/len(trainloader)}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch : 1, Loss : 2.2870395183563232\n",
            "Batch : 2, Loss : 2.304734468460083\n",
            "Batch : 3, Loss : 2.28812313079834\n",
            "Batch : 4, Loss : 2.2898640632629395\n",
            "Batch : 5, Loss : 2.2802863121032715\n",
            "Batch : 6, Loss : 2.2768282890319824\n",
            "Batch : 7, Loss : 2.2971038818359375\n",
            "Batch : 8, Loss : 2.272695779800415\n",
            "Batch : 9, Loss : 2.266519546508789\n",
            "Batch : 10, Loss : 2.276360273361206\n",
            "Batch : 11, Loss : 2.285900115966797\n",
            "Batch : 12, Loss : 2.2687723636627197\n",
            "Batch : 13, Loss : 2.2825448513031006\n",
            "Batch : 14, Loss : 2.269296407699585\n",
            "Batch : 15, Loss : 2.251699447631836\n",
            "Batch : 16, Loss : 2.2710673809051514\n",
            "Batch : 17, Loss : 2.2565464973449707\n",
            "Batch : 18, Loss : 2.247075080871582\n",
            "Batch : 19, Loss : 2.242631673812866\n",
            "Batch : 20, Loss : 2.2493398189544678\n",
            "Batch : 21, Loss : 2.2490806579589844\n",
            "Batch : 22, Loss : 2.239584445953369\n",
            "Batch : 23, Loss : 2.2394418716430664\n",
            "Batch : 24, Loss : 2.252643585205078\n",
            "Batch : 25, Loss : 2.2172629833221436\n",
            "Batch : 26, Loss : 2.236956834793091\n",
            "Batch : 27, Loss : 2.2230703830718994\n",
            "Batch : 28, Loss : 2.223057270050049\n",
            "Batch : 29, Loss : 2.197035074234009\n",
            "Batch : 30, Loss : 2.2178027629852295\n",
            "Batch : 31, Loss : 2.242530107498169\n",
            "Batch : 32, Loss : 2.223618507385254\n",
            "Batch : 33, Loss : 2.182101011276245\n",
            "Batch : 34, Loss : 2.1979775428771973\n",
            "Batch : 35, Loss : 2.219874382019043\n",
            "Batch : 36, Loss : 2.2039496898651123\n",
            "Batch : 37, Loss : 2.219465970993042\n",
            "Batch : 38, Loss : 2.1876096725463867\n",
            "Batch : 39, Loss : 2.1937692165374756\n",
            "Batch : 40, Loss : 2.199791193008423\n",
            "Batch : 41, Loss : 2.1997416019439697\n",
            "Batch : 42, Loss : 2.199578046798706\n",
            "Batch : 43, Loss : 2.166189432144165\n",
            "Batch : 44, Loss : 2.1731696128845215\n",
            "Batch : 45, Loss : 2.1663475036621094\n",
            "Batch : 46, Loss : 2.1630232334136963\n",
            "Batch : 47, Loss : 2.173583745956421\n",
            "Batch : 48, Loss : 2.166243314743042\n",
            "Batch : 49, Loss : 2.17478609085083\n",
            "Batch : 50, Loss : 2.1410579681396484\n",
            "Batch : 51, Loss : 2.132265329360962\n",
            "Batch : 52, Loss : 2.1887452602386475\n",
            "Batch : 53, Loss : 2.1620266437530518\n",
            "Batch : 54, Loss : 2.117699146270752\n",
            "Batch : 55, Loss : 2.141117572784424\n",
            "Batch : 56, Loss : 2.135773181915283\n",
            "Batch : 57, Loss : 2.1412599086761475\n",
            "Batch : 58, Loss : 2.1211438179016113\n",
            "Batch : 59, Loss : 2.103712320327759\n",
            "Batch : 60, Loss : 2.105754852294922\n",
            "Batch : 61, Loss : 2.1260485649108887\n",
            "Batch : 62, Loss : 2.0871195793151855\n",
            "Batch : 63, Loss : 2.0897393226623535\n",
            "Batch : 64, Loss : 2.1417412757873535\n",
            "Batch : 65, Loss : 2.0826640129089355\n",
            "Batch : 66, Loss : 2.086456298828125\n",
            "Batch : 67, Loss : 2.0807738304138184\n",
            "Batch : 68, Loss : 2.0981459617614746\n",
            "Batch : 69, Loss : 2.084650993347168\n",
            "Batch : 70, Loss : 2.0585594177246094\n",
            "Batch : 71, Loss : 2.083327054977417\n",
            "Batch : 72, Loss : 2.0672619342803955\n",
            "Batch : 73, Loss : 2.045077085494995\n",
            "Batch : 74, Loss : 2.0248615741729736\n",
            "Batch : 75, Loss : 2.0355846881866455\n",
            "Batch : 76, Loss : 2.0456814765930176\n",
            "Batch : 77, Loss : 2.042203664779663\n",
            "Batch : 78, Loss : 2.0114803314208984\n",
            "Batch : 79, Loss : 2.0007989406585693\n",
            "Batch : 80, Loss : 2.0284690856933594\n",
            "Batch : 81, Loss : 2.0503439903259277\n",
            "Batch : 82, Loss : 1.9999030828475952\n",
            "Batch : 83, Loss : 2.0404775142669678\n",
            "Batch : 84, Loss : 2.004279613494873\n",
            "Batch : 85, Loss : 2.0411429405212402\n",
            "Batch : 86, Loss : 1.98568594455719\n",
            "Batch : 87, Loss : 1.984741449356079\n",
            "Batch : 88, Loss : 1.9755622148513794\n",
            "Batch : 89, Loss : 1.9781358242034912\n",
            "Batch : 90, Loss : 1.971121907234192\n",
            "Batch : 91, Loss : 2.0088024139404297\n",
            "Batch : 92, Loss : 1.9533547163009644\n",
            "Batch : 93, Loss : 1.9273674488067627\n",
            "Batch : 94, Loss : 1.9663946628570557\n",
            "Batch : 95, Loss : 1.9294840097427368\n",
            "Batch : 96, Loss : 1.8992468118667603\n",
            "Batch : 97, Loss : 1.9139755964279175\n",
            "Batch : 98, Loss : 1.920300841331482\n",
            "Batch : 99, Loss : 1.893148422241211\n",
            "Batch : 100, Loss : 1.9020233154296875\n",
            "Batch : 101, Loss : 1.9861620664596558\n",
            "Batch : 102, Loss : 1.8941391706466675\n",
            "Batch : 103, Loss : 1.878528118133545\n",
            "Batch : 104, Loss : 1.8526650667190552\n",
            "Batch : 105, Loss : 1.8771803379058838\n",
            "Batch : 106, Loss : 1.8768731355667114\n",
            "Batch : 107, Loss : 1.8324781656265259\n",
            "Batch : 108, Loss : 1.8375011682510376\n",
            "Batch : 109, Loss : 1.8727120161056519\n",
            "Batch : 110, Loss : 1.8134828805923462\n",
            "Batch : 111, Loss : 1.8504548072814941\n",
            "Batch : 112, Loss : 1.8896410465240479\n",
            "Batch : 113, Loss : 1.8046207427978516\n",
            "Batch : 114, Loss : 1.8042620420455933\n",
            "Batch : 115, Loss : 1.7859387397766113\n",
            "Batch : 116, Loss : 1.7643966674804688\n",
            "Batch : 117, Loss : 1.773877501487732\n",
            "Batch : 118, Loss : 1.8144224882125854\n",
            "Batch : 119, Loss : 1.778023600578308\n",
            "Batch : 120, Loss : 1.7875747680664062\n",
            "Batch : 121, Loss : 1.7815160751342773\n",
            "Batch : 122, Loss : 1.7425154447555542\n",
            "Batch : 123, Loss : 1.6732897758483887\n",
            "Batch : 124, Loss : 1.8245290517807007\n",
            "Batch : 125, Loss : 1.7087002992630005\n",
            "Batch : 126, Loss : 1.7019673585891724\n",
            "Batch : 127, Loss : 1.721555471420288\n",
            "Batch : 128, Loss : 1.688834309577942\n",
            "Batch : 129, Loss : 1.735489845275879\n",
            "Batch : 130, Loss : 1.6645172834396362\n",
            "Batch : 131, Loss : 1.6880850791931152\n",
            "Batch : 132, Loss : 1.6604924201965332\n",
            "Batch : 133, Loss : 1.6661121845245361\n",
            "Batch : 134, Loss : 1.6280564069747925\n",
            "Batch : 135, Loss : 1.6878329515457153\n",
            "Batch : 136, Loss : 1.6056441068649292\n",
            "Batch : 137, Loss : 1.6899101734161377\n",
            "Batch : 138, Loss : 1.5744436979293823\n",
            "Batch : 139, Loss : 1.6058402061462402\n",
            "Batch : 140, Loss : 1.600780963897705\n",
            "Batch : 141, Loss : 1.5656628608703613\n",
            "Batch : 142, Loss : 1.630824327468872\n",
            "Batch : 143, Loss : 1.6335318088531494\n",
            "Batch : 144, Loss : 1.537968397140503\n",
            "Batch : 145, Loss : 1.589952826499939\n",
            "Batch : 146, Loss : 1.53298819065094\n",
            "Batch : 147, Loss : 1.5864728689193726\n",
            "Batch : 148, Loss : 1.5517463684082031\n",
            "Batch : 149, Loss : 1.6810373067855835\n",
            "Batch : 150, Loss : 1.5942589044570923\n",
            "Batch : 151, Loss : 1.5094536542892456\n",
            "Batch : 152, Loss : 1.5328160524368286\n",
            "Batch : 153, Loss : 1.5457831621170044\n",
            "Batch : 154, Loss : 1.4847909212112427\n",
            "Batch : 155, Loss : 1.5357012748718262\n",
            "Batch : 156, Loss : 1.4713897705078125\n",
            "Batch : 157, Loss : 1.547956943511963\n",
            "Batch : 158, Loss : 1.447540283203125\n",
            "Batch : 159, Loss : 1.4744549989700317\n",
            "Batch : 160, Loss : 1.5116565227508545\n",
            "Batch : 161, Loss : 1.4856828451156616\n",
            "Batch : 162, Loss : 1.391874074935913\n",
            "Batch : 163, Loss : 1.4790599346160889\n",
            "Batch : 164, Loss : 1.4736872911453247\n",
            "Batch : 165, Loss : 1.4298242330551147\n",
            "Batch : 166, Loss : 1.41767418384552\n",
            "Batch : 167, Loss : 1.5738030672073364\n",
            "Batch : 168, Loss : 1.4504848718643188\n",
            "Batch : 169, Loss : 1.4643326997756958\n",
            "Batch : 170, Loss : 1.4500443935394287\n",
            "Batch : 171, Loss : 1.3603771924972534\n",
            "Batch : 172, Loss : 1.4941645860671997\n",
            "Batch : 173, Loss : 1.3527286052703857\n",
            "Batch : 174, Loss : 1.4247959852218628\n",
            "Batch : 175, Loss : 1.4404929876327515\n",
            "Batch : 176, Loss : 1.3351829051971436\n",
            "Batch : 177, Loss : 1.4884059429168701\n",
            "Batch : 178, Loss : 1.448508858680725\n",
            "Batch : 179, Loss : 1.4672389030456543\n",
            "Batch : 180, Loss : 1.4081943035125732\n",
            "Batch : 181, Loss : 1.3293312788009644\n",
            "Batch : 182, Loss : 1.3573660850524902\n",
            "Batch : 183, Loss : 1.3603969812393188\n",
            "Batch : 184, Loss : 1.404849648475647\n",
            "Batch : 185, Loss : 1.3898038864135742\n",
            "Batch : 186, Loss : 1.3744629621505737\n",
            "Batch : 187, Loss : 1.4307760000228882\n",
            "Batch : 188, Loss : 1.3570908308029175\n",
            "Batch : 189, Loss : 1.2827564477920532\n",
            "Batch : 190, Loss : 1.2756606340408325\n",
            "Batch : 191, Loss : 1.2754038572311401\n",
            "Batch : 192, Loss : 1.2776992321014404\n",
            "Batch : 193, Loss : 1.2119128704071045\n",
            "Batch : 194, Loss : 1.2995885610580444\n",
            "Batch : 195, Loss : 1.3091521263122559\n",
            "Batch : 196, Loss : 1.449568748474121\n",
            "Batch : 197, Loss : 1.2857229709625244\n",
            "Batch : 198, Loss : 1.3289313316345215\n",
            "Batch : 199, Loss : 1.2628916501998901\n",
            "Batch : 200, Loss : 1.241918921470642\n",
            "Batch : 201, Loss : 1.248958945274353\n",
            "Batch : 202, Loss : 1.3038016557693481\n",
            "Batch : 203, Loss : 1.2043707370758057\n",
            "Batch : 204, Loss : 1.2874937057495117\n",
            "Batch : 205, Loss : 1.2431583404541016\n",
            "Batch : 206, Loss : 1.175491452217102\n",
            "Batch : 207, Loss : 1.2307859659194946\n",
            "Batch : 208, Loss : 1.1404945850372314\n",
            "Batch : 209, Loss : 1.36781644821167\n",
            "Batch : 210, Loss : 1.261942744255066\n",
            "Batch : 211, Loss : 1.1684428453445435\n",
            "Batch : 212, Loss : 1.319818377494812\n",
            "Batch : 213, Loss : 1.0796617269515991\n",
            "Batch : 214, Loss : 1.117333173751831\n",
            "Batch : 215, Loss : 1.2286982536315918\n",
            "Batch : 216, Loss : 1.1974061727523804\n",
            "Batch : 217, Loss : 1.20839524269104\n",
            "Batch : 218, Loss : 1.2510026693344116\n",
            "Batch : 219, Loss : 1.0543642044067383\n",
            "Batch : 220, Loss : 1.2688977718353271\n",
            "Batch : 221, Loss : 1.2789627313613892\n",
            "Batch : 222, Loss : 1.2129831314086914\n",
            "Batch : 223, Loss : 1.1825495958328247\n",
            "Batch : 224, Loss : 1.1791728734970093\n",
            "Batch : 225, Loss : 1.3311454057693481\n",
            "Batch : 226, Loss : 1.1154332160949707\n",
            "Batch : 227, Loss : 1.1277803182601929\n",
            "Batch : 228, Loss : 1.0481840372085571\n",
            "Batch : 229, Loss : 1.1764765977859497\n",
            "Batch : 230, Loss : 1.2211635112762451\n",
            "Batch : 231, Loss : 1.3000301122665405\n",
            "Batch : 232, Loss : 1.150438904762268\n",
            "Batch : 233, Loss : 1.1533280611038208\n",
            "Batch : 234, Loss : 1.100498914718628\n",
            "Batch : 235, Loss : 1.1316131353378296\n",
            "Batch : 236, Loss : 1.0922712087631226\n",
            "Batch : 237, Loss : 1.2444618940353394\n",
            "Batch : 238, Loss : 1.0989309549331665\n",
            "Batch : 239, Loss : 1.1379446983337402\n",
            "Batch : 240, Loss : 1.1280683279037476\n",
            "Batch : 241, Loss : 1.2034032344818115\n",
            "Batch : 242, Loss : 1.1087865829467773\n",
            "Batch : 243, Loss : 1.1837549209594727\n",
            "Batch : 244, Loss : 1.1745150089263916\n",
            "Batch : 245, Loss : 1.1264530420303345\n",
            "Batch : 246, Loss : 1.1874589920043945\n",
            "Batch : 247, Loss : 1.141237735748291\n",
            "Batch : 248, Loss : 1.086282730102539\n",
            "Batch : 249, Loss : 0.9838451743125916\n",
            "Batch : 250, Loss : 1.0993828773498535\n",
            "Batch : 251, Loss : 1.025924801826477\n",
            "Batch : 252, Loss : 1.0281436443328857\n",
            "Batch : 253, Loss : 1.0866392850875854\n",
            "Batch : 254, Loss : 1.0587565898895264\n",
            "Batch : 255, Loss : 1.0446606874465942\n",
            "Batch : 256, Loss : 1.1647034883499146\n",
            "Batch : 257, Loss : 1.0904687643051147\n",
            "Batch : 258, Loss : 0.9964816570281982\n",
            "Batch : 259, Loss : 1.0643830299377441\n",
            "Batch : 260, Loss : 1.0763888359069824\n",
            "Batch : 261, Loss : 1.0360620021820068\n",
            "Batch : 262, Loss : 1.0996195077896118\n",
            "Batch : 263, Loss : 0.9848842024803162\n",
            "Batch : 264, Loss : 1.0447564125061035\n",
            "Batch : 265, Loss : 1.0897972583770752\n",
            "Batch : 266, Loss : 1.0932658910751343\n",
            "Batch : 267, Loss : 1.1169188022613525\n",
            "Batch : 268, Loss : 1.1510084867477417\n",
            "Batch : 269, Loss : 1.0899858474731445\n",
            "Batch : 270, Loss : 1.1003684997558594\n",
            "Batch : 271, Loss : 1.0718185901641846\n",
            "Batch : 272, Loss : 1.0314891338348389\n",
            "Batch : 273, Loss : 1.048856258392334\n",
            "Batch : 274, Loss : 1.1296474933624268\n",
            "Batch : 275, Loss : 1.0038374662399292\n",
            "Batch : 276, Loss : 1.1300562620162964\n",
            "Batch : 277, Loss : 1.0546988248825073\n",
            "Batch : 278, Loss : 1.1145440340042114\n",
            "Batch : 279, Loss : 1.0150395631790161\n",
            "Batch : 280, Loss : 1.0460823774337769\n",
            "Batch : 281, Loss : 1.133905053138733\n",
            "Batch : 282, Loss : 0.9761397838592529\n",
            "Batch : 283, Loss : 1.0654855966567993\n",
            "Batch : 284, Loss : 0.9209386110305786\n",
            "Batch : 285, Loss : 1.0804563760757446\n",
            "Batch : 286, Loss : 0.9702053070068359\n",
            "Batch : 287, Loss : 0.9916998744010925\n",
            "Batch : 288, Loss : 0.9429059028625488\n",
            "Batch : 289, Loss : 1.0510585308074951\n",
            "Batch : 290, Loss : 0.9330576062202454\n",
            "Batch : 291, Loss : 1.021963119506836\n",
            "Batch : 292, Loss : 1.046377182006836\n",
            "Batch : 293, Loss : 1.0180580615997314\n",
            "Batch : 294, Loss : 1.0389325618743896\n",
            "Batch : 295, Loss : 1.0386883020401\n",
            "Batch : 296, Loss : 1.0100034475326538\n",
            "Batch : 297, Loss : 0.9653145670890808\n",
            "Batch : 298, Loss : 0.9908826947212219\n",
            "Batch : 299, Loss : 1.0952626466751099\n",
            "Batch : 300, Loss : 0.9550237655639648\n",
            "Batch : 301, Loss : 0.8943005204200745\n",
            "Batch : 302, Loss : 1.0014897584915161\n",
            "Batch : 303, Loss : 1.0458163022994995\n",
            "Batch : 304, Loss : 0.9903905987739563\n",
            "Batch : 305, Loss : 0.9286476373672485\n",
            "Batch : 306, Loss : 0.8939067721366882\n",
            "Batch : 307, Loss : 1.0463809967041016\n",
            "Batch : 308, Loss : 0.9978640675544739\n",
            "Batch : 309, Loss : 0.9948023557662964\n",
            "Batch : 310, Loss : 1.023533821105957\n",
            "Batch : 311, Loss : 0.8400972485542297\n",
            "Batch : 312, Loss : 0.9030290842056274\n",
            "Batch : 313, Loss : 1.035967469215393\n",
            "Batch : 314, Loss : 0.8487675189971924\n",
            "Batch : 315, Loss : 1.0311150550842285\n",
            "Batch : 316, Loss : 0.8895661234855652\n",
            "Batch : 317, Loss : 0.9951992034912109\n",
            "Batch : 318, Loss : 0.9706234335899353\n",
            "Batch : 319, Loss : 0.8424338698387146\n",
            "Batch : 320, Loss : 1.0455260276794434\n",
            "Batch : 321, Loss : 0.9383735656738281\n",
            "Batch : 322, Loss : 0.9427369832992554\n",
            "Batch : 323, Loss : 1.075688123703003\n",
            "Batch : 324, Loss : 0.8923086524009705\n",
            "Batch : 325, Loss : 0.8994676470756531\n",
            "Batch : 326, Loss : 0.8153958320617676\n",
            "Batch : 327, Loss : 0.8237111568450928\n",
            "Batch : 328, Loss : 0.9863256216049194\n",
            "Batch : 329, Loss : 0.8959795832633972\n",
            "Batch : 330, Loss : 0.8395307064056396\n",
            "Batch : 331, Loss : 0.8635518550872803\n",
            "Batch : 332, Loss : 0.9945636987686157\n",
            "Batch : 333, Loss : 0.8419990539550781\n",
            "Batch : 334, Loss : 0.9896140098571777\n",
            "Batch : 335, Loss : 0.9663031101226807\n",
            "Batch : 336, Loss : 0.9501408338546753\n",
            "Batch : 337, Loss : 0.9832561612129211\n",
            "Batch : 338, Loss : 0.8759270906448364\n",
            "Batch : 339, Loss : 0.8855599761009216\n",
            "Batch : 340, Loss : 0.9511671662330627\n",
            "Batch : 341, Loss : 0.9434155821800232\n",
            "Batch : 342, Loss : 0.748958945274353\n",
            "Batch : 343, Loss : 0.8747463822364807\n",
            "Batch : 344, Loss : 1.0233330726623535\n",
            "Batch : 345, Loss : 0.8393927216529846\n",
            "Batch : 346, Loss : 0.8568965196609497\n",
            "Batch : 347, Loss : 0.8220869898796082\n",
            "Batch : 348, Loss : 0.8316198587417603\n",
            "Batch : 349, Loss : 0.9496217966079712\n",
            "Batch : 350, Loss : 0.9732937812805176\n",
            "Batch : 351, Loss : 0.8508378267288208\n",
            "Batch : 352, Loss : 0.8345123529434204\n",
            "Batch : 353, Loss : 1.0469069480895996\n",
            "Batch : 354, Loss : 0.993888795375824\n",
            "Batch : 355, Loss : 0.8273106217384338\n",
            "Batch : 356, Loss : 0.8228092789649963\n",
            "Batch : 357, Loss : 0.9246159195899963\n",
            "Batch : 358, Loss : 0.8254827260971069\n",
            "Batch : 359, Loss : 0.9216403365135193\n",
            "Batch : 360, Loss : 1.1146397590637207\n",
            "Batch : 361, Loss : 0.9136505126953125\n",
            "Batch : 362, Loss : 1.0562025308609009\n",
            "Batch : 363, Loss : 0.8876919150352478\n",
            "Batch : 364, Loss : 0.9641982913017273\n",
            "Batch : 365, Loss : 1.0136334896087646\n",
            "Batch : 366, Loss : 0.9114506840705872\n",
            "Batch : 367, Loss : 0.9671555161476135\n",
            "Batch : 368, Loss : 0.8182324171066284\n",
            "Batch : 369, Loss : 0.6988208293914795\n",
            "Batch : 370, Loss : 0.8112639784812927\n",
            "Batch : 371, Loss : 1.025213360786438\n",
            "Batch : 372, Loss : 0.9694569706916809\n",
            "Batch : 373, Loss : 0.7631861567497253\n",
            "Batch : 374, Loss : 0.911118745803833\n",
            "Batch : 375, Loss : 0.8206062316894531\n",
            "Batch : 376, Loss : 0.855167806148529\n",
            "Batch : 377, Loss : 0.7868536710739136\n",
            "Batch : 378, Loss : 1.027243971824646\n",
            "Batch : 379, Loss : 0.8710141181945801\n",
            "Batch : 380, Loss : 0.9744880795478821\n",
            "Batch : 381, Loss : 0.8644775748252869\n",
            "Batch : 382, Loss : 0.7653881907463074\n",
            "Batch : 383, Loss : 0.8527953624725342\n",
            "Batch : 384, Loss : 0.951998233795166\n",
            "Batch : 385, Loss : 0.8120945692062378\n",
            "Batch : 386, Loss : 0.9898700714111328\n",
            "Batch : 387, Loss : 0.9574662446975708\n",
            "Batch : 388, Loss : 0.8777622580528259\n",
            "Batch : 389, Loss : 0.7408223748207092\n",
            "Batch : 390, Loss : 0.8576185703277588\n",
            "Batch : 391, Loss : 0.8054349422454834\n",
            "Batch : 392, Loss : 0.8061041831970215\n",
            "Batch : 393, Loss : 0.8291417956352234\n",
            "Batch : 394, Loss : 0.9051896333694458\n",
            "Batch : 395, Loss : 0.8608606457710266\n",
            "Batch : 396, Loss : 0.7163163423538208\n",
            "Batch : 397, Loss : 0.714282751083374\n",
            "Batch : 398, Loss : 0.7770115733146667\n",
            "Batch : 399, Loss : 0.7763680219650269\n",
            "Batch : 400, Loss : 0.7846837043762207\n",
            "Batch : 401, Loss : 0.7017775177955627\n",
            "Batch : 402, Loss : 0.7163568735122681\n",
            "Batch : 403, Loss : 0.8036866188049316\n",
            "Batch : 404, Loss : 0.8700047135353088\n",
            "Batch : 405, Loss : 0.7051833271980286\n",
            "Batch : 406, Loss : 0.8674827218055725\n",
            "Batch : 407, Loss : 0.9440911412239075\n",
            "Batch : 408, Loss : 0.7975640296936035\n",
            "Batch : 409, Loss : 0.7597708106040955\n",
            "Batch : 410, Loss : 0.8811910152435303\n",
            "Batch : 411, Loss : 0.7682101726531982\n",
            "Batch : 412, Loss : 0.8312892913818359\n",
            "Batch : 413, Loss : 0.9950111508369446\n",
            "Batch : 414, Loss : 0.7928733229637146\n",
            "Batch : 415, Loss : 0.8652892708778381\n",
            "Batch : 416, Loss : 0.8445220589637756\n",
            "Batch : 417, Loss : 0.7971892952919006\n",
            "Batch : 418, Loss : 0.7811798453330994\n",
            "Batch : 419, Loss : 0.831779420375824\n",
            "Batch : 420, Loss : 0.8178723454475403\n",
            "Batch : 421, Loss : 0.8016936779022217\n",
            "Batch : 422, Loss : 0.7927845120429993\n",
            "Batch : 423, Loss : 0.8812825679779053\n",
            "Batch : 424, Loss : 0.9165083765983582\n",
            "Batch : 425, Loss : 0.8030468225479126\n",
            "Batch : 426, Loss : 0.8350710868835449\n",
            "Batch : 427, Loss : 0.6937257051467896\n",
            "Batch : 428, Loss : 0.6264476776123047\n",
            "Batch : 429, Loss : 0.9206298589706421\n",
            "Batch : 430, Loss : 0.8028851747512817\n",
            "Batch : 431, Loss : 0.8649357557296753\n",
            "Batch : 432, Loss : 0.757881224155426\n",
            "Batch : 433, Loss : 0.8830479383468628\n",
            "Batch : 434, Loss : 0.8506214022636414\n",
            "Batch : 435, Loss : 0.9666618704795837\n",
            "Batch : 436, Loss : 0.8275165557861328\n",
            "Batch : 437, Loss : 0.8999882340431213\n",
            "Batch : 438, Loss : 0.892723798751831\n",
            "Batch : 439, Loss : 0.6166831254959106\n",
            "Batch : 440, Loss : 0.7642669677734375\n",
            "Batch : 441, Loss : 0.8490658402442932\n",
            "Batch : 442, Loss : 0.6933459639549255\n",
            "Batch : 443, Loss : 0.8156618475914001\n",
            "Batch : 444, Loss : 1.0391743183135986\n",
            "Batch : 445, Loss : 0.7407516241073608\n",
            "Batch : 446, Loss : 0.8544924855232239\n",
            "Batch : 447, Loss : 0.7371220588684082\n",
            "Batch : 448, Loss : 0.9395984411239624\n",
            "Batch : 449, Loss : 0.7362275719642639\n",
            "Batch : 450, Loss : 0.7123757004737854\n",
            "Batch : 451, Loss : 0.9103202819824219\n",
            "Batch : 452, Loss : 1.0294570922851562\n",
            "Batch : 453, Loss : 0.8122186660766602\n",
            "Batch : 454, Loss : 0.6819758415222168\n",
            "Batch : 455, Loss : 0.7055825591087341\n",
            "Batch : 456, Loss : 0.7316321134567261\n",
            "Batch : 457, Loss : 0.758821427822113\n",
            "Batch : 458, Loss : 0.5051584839820862\n",
            "Batch : 459, Loss : 0.6925161480903625\n",
            "Batch : 460, Loss : 0.8025453090667725\n",
            "Batch : 461, Loss : 0.8681058287620544\n",
            "Batch : 462, Loss : 0.6757441163063049\n",
            "Batch : 463, Loss : 1.0154447555541992\n",
            "Batch : 464, Loss : 0.9154059290885925\n",
            "Batch : 465, Loss : 0.8268671035766602\n",
            "Batch : 466, Loss : 0.926138699054718\n",
            "Batch : 467, Loss : 0.7050589323043823\n",
            "Batch : 468, Loss : 0.772429347038269\n",
            "Batch : 469, Loss : 0.7982624173164368\n",
            "Batch : 470, Loss : 0.650049090385437\n",
            "Batch : 471, Loss : 0.8577596545219421\n",
            "Batch : 472, Loss : 0.6799082159996033\n",
            "Batch : 473, Loss : 0.6845793724060059\n",
            "Batch : 474, Loss : 0.8157044053077698\n",
            "Batch : 475, Loss : 0.9985666871070862\n",
            "Batch : 476, Loss : 0.7091845273971558\n",
            "Batch : 477, Loss : 0.8300144076347351\n",
            "Batch : 478, Loss : 0.7109655141830444\n",
            "Batch : 479, Loss : 0.9295163154602051\n",
            "Batch : 480, Loss : 0.7382053136825562\n",
            "Batch : 481, Loss : 0.825282871723175\n",
            "Batch : 482, Loss : 0.6786476969718933\n",
            "Batch : 483, Loss : 0.8040444850921631\n",
            "Batch : 484, Loss : 0.6891704201698303\n",
            "Batch : 485, Loss : 0.707054615020752\n",
            "Batch : 486, Loss : 0.7267826199531555\n",
            "Batch : 487, Loss : 0.6618626713752747\n",
            "Batch : 488, Loss : 0.6717351675033569\n",
            "Batch : 489, Loss : 0.8216107487678528\n",
            "Batch : 490, Loss : 0.6027728319168091\n",
            "Batch : 491, Loss : 0.768230140209198\n",
            "Batch : 492, Loss : 0.5616267919540405\n",
            "Batch : 493, Loss : 0.7680937051773071\n",
            "Batch : 494, Loss : 0.7308448553085327\n",
            "Batch : 495, Loss : 0.7197011113166809\n",
            "Batch : 496, Loss : 0.821844220161438\n",
            "Batch : 497, Loss : 0.6384657025337219\n",
            "Batch : 498, Loss : 0.7569140791893005\n",
            "Batch : 499, Loss : 0.9128819704055786\n",
            "Batch : 500, Loss : 0.7631595730781555\n",
            "Batch : 501, Loss : 0.6968014240264893\n",
            "Batch : 502, Loss : 0.8026309013366699\n",
            "Batch : 503, Loss : 0.7279921174049377\n",
            "Batch : 504, Loss : 0.6625187397003174\n",
            "Batch : 505, Loss : 0.7103954553604126\n",
            "Batch : 506, Loss : 0.8843944668769836\n",
            "Batch : 507, Loss : 0.6496283411979675\n",
            "Batch : 508, Loss : 0.9447163343429565\n",
            "Batch : 509, Loss : 0.7728186249732971\n",
            "Batch : 510, Loss : 0.7125142216682434\n",
            "Batch : 511, Loss : 0.891055703163147\n",
            "Batch : 512, Loss : 0.7189643383026123\n",
            "Batch : 513, Loss : 0.747040867805481\n",
            "Batch : 514, Loss : 0.8481554388999939\n",
            "Batch : 515, Loss : 0.8862082362174988\n",
            "Batch : 516, Loss : 0.7309467792510986\n",
            "Batch : 517, Loss : 0.7483436465263367\n",
            "Batch : 518, Loss : 0.7538427114486694\n",
            "Batch : 519, Loss : 0.8463104963302612\n",
            "Batch : 520, Loss : 0.8045957684516907\n",
            "Batch : 521, Loss : 0.7899759411811829\n",
            "Batch : 522, Loss : 0.6881920695304871\n",
            "Batch : 523, Loss : 0.8228352665901184\n",
            "Batch : 524, Loss : 0.5744777321815491\n",
            "Batch : 525, Loss : 0.6765052676200867\n",
            "Batch : 526, Loss : 0.7733563780784607\n",
            "Batch : 527, Loss : 0.702908456325531\n",
            "Batch : 528, Loss : 0.6234713792800903\n",
            "Batch : 529, Loss : 0.6949124932289124\n",
            "Batch : 530, Loss : 0.6462811231613159\n",
            "Batch : 531, Loss : 0.6704252362251282\n",
            "Batch : 532, Loss : 0.8544533848762512\n",
            "Batch : 533, Loss : 0.6024919748306274\n",
            "Batch : 534, Loss : 0.6478753685951233\n",
            "Batch : 535, Loss : 0.8312225341796875\n",
            "Batch : 536, Loss : 0.7630383968353271\n",
            "Batch : 537, Loss : 0.7018898725509644\n",
            "Batch : 538, Loss : 0.6334014534950256\n",
            "Batch : 539, Loss : 0.7255592942237854\n",
            "Batch : 540, Loss : 0.772726833820343\n",
            "Batch : 541, Loss : 0.7674815058708191\n",
            "Batch : 542, Loss : 0.7241008877754211\n",
            "Batch : 543, Loss : 0.6324021220207214\n",
            "Batch : 544, Loss : 0.6427000164985657\n",
            "Batch : 545, Loss : 0.7284027934074402\n",
            "Batch : 546, Loss : 0.6933210492134094\n",
            "Batch : 547, Loss : 0.7117827534675598\n",
            "Batch : 548, Loss : 0.7979455590248108\n",
            "Batch : 549, Loss : 0.8950966596603394\n",
            "Batch : 550, Loss : 0.7324565052986145\n",
            "Batch : 551, Loss : 0.7410070300102234\n",
            "Batch : 552, Loss : 0.6817288398742676\n",
            "Batch : 553, Loss : 0.7889116406440735\n",
            "Batch : 554, Loss : 0.7910628318786621\n",
            "Batch : 555, Loss : 0.6948679685592651\n",
            "Batch : 556, Loss : 0.6583847999572754\n",
            "Batch : 557, Loss : 0.6872433423995972\n",
            "Batch : 558, Loss : 0.6916077136993408\n",
            "Batch : 559, Loss : 0.7684161067008972\n",
            "Batch : 560, Loss : 0.8262228965759277\n",
            "Batch : 561, Loss : 0.8625297546386719\n",
            "Batch : 562, Loss : 0.7535915970802307\n",
            "Batch : 563, Loss : 0.8230611681938171\n",
            "Batch : 564, Loss : 0.8453679084777832\n",
            "Batch : 565, Loss : 0.6721875667572021\n",
            "Batch : 566, Loss : 0.6994532942771912\n",
            "Batch : 567, Loss : 0.5577316284179688\n",
            "Batch : 568, Loss : 0.6488110423088074\n",
            "Batch : 569, Loss : 0.6631966233253479\n",
            "Batch : 570, Loss : 0.7153787016868591\n",
            "Batch : 571, Loss : 0.7294431328773499\n",
            "Batch : 572, Loss : 0.6075177192687988\n",
            "Batch : 573, Loss : 0.6286693215370178\n",
            "Batch : 574, Loss : 0.7059420347213745\n",
            "Batch : 575, Loss : 0.8423635363578796\n",
            "Batch : 576, Loss : 0.8547047972679138\n",
            "Batch : 577, Loss : 0.7745809555053711\n",
            "Batch : 578, Loss : 0.7536949515342712\n",
            "Batch : 579, Loss : 0.7573085427284241\n",
            "Batch : 580, Loss : 0.6757764220237732\n",
            "Batch : 581, Loss : 0.839031457901001\n",
            "Batch : 582, Loss : 0.8354365825653076\n",
            "Batch : 583, Loss : 0.7210214138031006\n",
            "Batch : 584, Loss : 0.5639830827713013\n",
            "Batch : 585, Loss : 0.9781885147094727\n",
            "Batch : 586, Loss : 0.7759237289428711\n",
            "Batch : 587, Loss : 0.8212795853614807\n",
            "Batch : 588, Loss : 0.7597247958183289\n",
            "Batch : 589, Loss : 0.49362924695014954\n",
            "Batch : 590, Loss : 0.7240113615989685\n",
            "Batch : 591, Loss : 0.7132059931755066\n",
            "Batch : 592, Loss : 0.5552791357040405\n",
            "Batch : 593, Loss : 0.8183515071868896\n",
            "Batch : 594, Loss : 0.7880317568778992\n",
            "Batch : 595, Loss : 0.5756944417953491\n",
            "Batch : 596, Loss : 0.57582026720047\n",
            "Batch : 597, Loss : 0.7144548892974854\n",
            "Batch : 598, Loss : 0.7754212617874146\n",
            "Batch : 599, Loss : 0.8483291268348694\n",
            "Batch : 600, Loss : 0.552912712097168\n",
            "Batch : 601, Loss : 0.7413420677185059\n",
            "Batch : 602, Loss : 0.69488126039505\n",
            "Batch : 603, Loss : 0.6642267107963562\n",
            "Batch : 604, Loss : 0.8878339529037476\n",
            "Batch : 605, Loss : 0.6677665710449219\n",
            "Batch : 606, Loss : 0.5105552077293396\n",
            "Batch : 607, Loss : 0.5617390871047974\n",
            "Batch : 608, Loss : 0.8441222906112671\n",
            "Batch : 609, Loss : 0.6426936984062195\n",
            "Batch : 610, Loss : 0.6830936074256897\n",
            "Batch : 611, Loss : 0.6516925692558289\n",
            "Batch : 612, Loss : 0.48584046959877014\n",
            "Batch : 613, Loss : 0.7503786087036133\n",
            "Batch : 614, Loss : 0.675473153591156\n",
            "Batch : 615, Loss : 0.7284165024757385\n",
            "Batch : 616, Loss : 0.9157969951629639\n",
            "Batch : 617, Loss : 0.5886196494102478\n",
            "Batch : 618, Loss : 0.6076081395149231\n",
            "Batch : 619, Loss : 0.6673130393028259\n",
            "Batch : 620, Loss : 0.6236943602561951\n",
            "Batch : 621, Loss : 0.6794784665107727\n",
            "Batch : 622, Loss : 0.658473551273346\n",
            "Batch : 623, Loss : 0.8497694134712219\n",
            "Batch : 624, Loss : 0.6827038526535034\n",
            "Batch : 625, Loss : 0.7280632853507996\n",
            "Batch : 626, Loss : 0.701410174369812\n",
            "Batch : 627, Loss : 0.8913046717643738\n",
            "Batch : 628, Loss : 0.5711582899093628\n",
            "Batch : 629, Loss : 0.8698960542678833\n",
            "Batch : 630, Loss : 0.8799493908882141\n",
            "Batch : 631, Loss : 0.855912983417511\n",
            "Batch : 632, Loss : 0.7074511051177979\n",
            "Batch : 633, Loss : 0.7025405168533325\n",
            "Batch : 634, Loss : 0.5994635224342346\n",
            "Batch : 635, Loss : 0.6680801510810852\n",
            "Batch : 636, Loss : 0.6104199290275574\n",
            "Batch : 637, Loss : 0.5193823575973511\n",
            "Batch : 638, Loss : 0.5966363549232483\n",
            "Batch : 639, Loss : 0.7871381640434265\n",
            "Batch : 640, Loss : 0.807651162147522\n",
            "Batch : 641, Loss : 0.6794544458389282\n",
            "Batch : 642, Loss : 0.6154255867004395\n",
            "Batch : 643, Loss : 0.6087794303894043\n",
            "Batch : 644, Loss : 0.783981442451477\n",
            "Batch : 645, Loss : 0.6996849775314331\n",
            "Batch : 646, Loss : 0.866692841053009\n",
            "Batch : 647, Loss : 0.6604658365249634\n",
            "Batch : 648, Loss : 0.6319520473480225\n",
            "Batch : 649, Loss : 0.5797567963600159\n",
            "Batch : 650, Loss : 0.7729020714759827\n",
            "Batch : 651, Loss : 0.6253669261932373\n",
            "Batch : 652, Loss : 0.6406689882278442\n",
            "Batch : 653, Loss : 0.6214686632156372\n",
            "Batch : 654, Loss : 0.8042336702346802\n",
            "Batch : 655, Loss : 0.5760464072227478\n",
            "Batch : 656, Loss : 0.890587568283081\n",
            "Batch : 657, Loss : 0.6244979500770569\n",
            "Batch : 658, Loss : 0.6511204838752747\n",
            "Batch : 659, Loss : 0.7974969148635864\n",
            "Batch : 660, Loss : 0.801396906375885\n",
            "Batch : 661, Loss : 0.6937323212623596\n",
            "Batch : 662, Loss : 0.7062658071517944\n",
            "Batch : 663, Loss : 0.8472793102264404\n",
            "Batch : 664, Loss : 0.770392894744873\n",
            "Batch : 665, Loss : 0.5798226594924927\n",
            "Batch : 666, Loss : 0.6431007981300354\n",
            "Batch : 667, Loss : 0.5608986616134644\n",
            "Batch : 668, Loss : 0.7276005148887634\n",
            "Batch : 669, Loss : 0.8257396221160889\n",
            "Batch : 670, Loss : 0.7078827619552612\n",
            "Batch : 671, Loss : 0.7609058618545532\n",
            "Batch : 672, Loss : 0.687503457069397\n",
            "Batch : 673, Loss : 0.807783305644989\n",
            "Batch : 674, Loss : 0.5494709610939026\n",
            "Batch : 675, Loss : 0.5690588355064392\n",
            "Batch : 676, Loss : 0.7318822741508484\n",
            "Batch : 677, Loss : 0.6610685586929321\n",
            "Batch : 678, Loss : 0.6059677600860596\n",
            "Batch : 679, Loss : 0.757122814655304\n",
            "Batch : 680, Loss : 0.7821720838546753\n",
            "Batch : 681, Loss : 0.8076022863388062\n",
            "Batch : 682, Loss : 0.6411091685295105\n",
            "Batch : 683, Loss : 0.6522238254547119\n",
            "Batch : 684, Loss : 0.6757621765136719\n",
            "Batch : 685, Loss : 0.6561817526817322\n",
            "Batch : 686, Loss : 0.622389554977417\n",
            "Batch : 687, Loss : 0.7800046801567078\n",
            "Batch : 688, Loss : 0.6412132978439331\n",
            "Batch : 689, Loss : 0.6015673279762268\n",
            "Batch : 690, Loss : 0.6835525631904602\n",
            "Batch : 691, Loss : 0.691862940788269\n",
            "Batch : 692, Loss : 0.7473742961883545\n",
            "Batch : 693, Loss : 0.6435567140579224\n",
            "Batch : 694, Loss : 0.7751424312591553\n",
            "Batch : 695, Loss : 0.6228098273277283\n",
            "Batch : 696, Loss : 0.7775972485542297\n",
            "Batch : 697, Loss : 0.8921300768852234\n",
            "Batch : 698, Loss : 0.7013864517211914\n",
            "Batch : 699, Loss : 0.6989784836769104\n",
            "Batch : 700, Loss : 0.5417435765266418\n",
            "Batch : 701, Loss : 0.608455240726471\n",
            "Batch : 702, Loss : 0.5610314607620239\n",
            "Batch : 703, Loss : 0.7050120830535889\n",
            "Batch : 704, Loss : 0.7836713194847107\n",
            "Batch : 705, Loss : 0.7030957937240601\n",
            "Batch : 706, Loss : 0.7734493017196655\n",
            "Batch : 707, Loss : 0.7992775440216064\n",
            "Batch : 708, Loss : 0.6449379920959473\n",
            "Batch : 709, Loss : 0.5217719674110413\n",
            "Batch : 710, Loss : 0.7311072945594788\n",
            "Batch : 711, Loss : 0.6857845783233643\n",
            "Batch : 712, Loss : 0.5681753754615784\n",
            "Batch : 713, Loss : 0.7596567869186401\n",
            "Batch : 714, Loss : 0.6375693082809448\n",
            "Batch : 715, Loss : 0.5372788310050964\n",
            "Batch : 716, Loss : 0.7728621959686279\n",
            "Batch : 717, Loss : 0.6817848682403564\n",
            "Batch : 718, Loss : 0.591252863407135\n",
            "Batch : 719, Loss : 0.6281984448432922\n",
            "Batch : 720, Loss : 0.5855292081832886\n",
            "Batch : 721, Loss : 0.5157657861709595\n",
            "Batch : 722, Loss : 0.5785235166549683\n",
            "Batch : 723, Loss : 0.7684946060180664\n",
            "Batch : 724, Loss : 0.5463510155677795\n",
            "Batch : 725, Loss : 0.5219321250915527\n",
            "Batch : 726, Loss : 0.7222204208374023\n",
            "Batch : 727, Loss : 0.5738531947135925\n",
            "Batch : 728, Loss : 0.719338059425354\n",
            "Batch : 729, Loss : 0.5601120591163635\n",
            "Batch : 730, Loss : 0.8211207389831543\n",
            "Batch : 731, Loss : 0.6453250646591187\n",
            "Batch : 732, Loss : 0.6953883767127991\n",
            "Batch : 733, Loss : 0.5901138782501221\n",
            "Batch : 734, Loss : 0.8846251964569092\n",
            "Batch : 735, Loss : 0.5756224393844604\n",
            "Batch : 736, Loss : 0.7365543842315674\n",
            "Batch : 737, Loss : 0.6784231662750244\n",
            "Batch : 738, Loss : 0.5872592329978943\n",
            "Batch : 739, Loss : 0.6442677974700928\n",
            "Batch : 740, Loss : 0.6038498282432556\n",
            "Batch : 741, Loss : 0.724298357963562\n",
            "Batch : 742, Loss : 0.668844997882843\n",
            "Batch : 743, Loss : 0.5151470303535461\n",
            "Batch : 744, Loss : 0.5529219508171082\n",
            "Batch : 745, Loss : 0.5518788695335388\n",
            "Batch : 746, Loss : 0.5992393493652344\n",
            "Batch : 747, Loss : 0.6568929553031921\n",
            "Batch : 748, Loss : 0.7783089876174927\n",
            "Batch : 749, Loss : 0.7212000489234924\n",
            "Batch : 750, Loss : 0.8227930665016174\n",
            "Batch : 751, Loss : 0.7234252691268921\n",
            "Batch : 752, Loss : 0.7376670241355896\n",
            "Batch : 753, Loss : 0.7477909326553345\n",
            "Batch : 754, Loss : 0.5696338415145874\n",
            "Batch : 755, Loss : 0.6932493448257446\n",
            "Batch : 756, Loss : 0.5893104076385498\n",
            "Batch : 757, Loss : 0.7852343916893005\n",
            "Batch : 758, Loss : 0.743565559387207\n",
            "Batch : 759, Loss : 0.5101660490036011\n",
            "Batch : 760, Loss : 0.5709818601608276\n",
            "Batch : 761, Loss : 0.6169514060020447\n",
            "Batch : 762, Loss : 0.6128961443901062\n",
            "Batch : 763, Loss : 0.7918534874916077\n",
            "Batch : 764, Loss : 0.5195525884628296\n",
            "Batch : 765, Loss : 0.7498835325241089\n",
            "Batch : 766, Loss : 0.6640720963478088\n",
            "Batch : 767, Loss : 0.4937218725681305\n",
            "Batch : 768, Loss : 0.8070046901702881\n",
            "Batch : 769, Loss : 0.8166646361351013\n",
            "Batch : 770, Loss : 0.8258249759674072\n",
            "Batch : 771, Loss : 0.6553702354431152\n",
            "Batch : 772, Loss : 0.789630115032196\n",
            "Batch : 773, Loss : 0.6931951642036438\n",
            "Batch : 774, Loss : 0.8822541236877441\n",
            "Batch : 775, Loss : 0.6766056418418884\n",
            "Batch : 776, Loss : 0.7389878630638123\n",
            "Batch : 777, Loss : 0.805167555809021\n",
            "Batch : 778, Loss : 0.5683875679969788\n",
            "Batch : 779, Loss : 0.7346060872077942\n",
            "Batch : 780, Loss : 0.5793524384498596\n",
            "Batch : 781, Loss : 0.6273390054702759\n",
            "Batch : 782, Loss : 0.5736602544784546\n",
            "Batch : 783, Loss : 0.7511411905288696\n",
            "Batch : 784, Loss : 0.5832415819168091\n",
            "Batch : 785, Loss : 0.7028903365135193\n",
            "Batch : 786, Loss : 0.6133670806884766\n",
            "Batch : 787, Loss : 0.7157946228981018\n",
            "Batch : 788, Loss : 0.7580891251564026\n",
            "Batch : 789, Loss : 0.5602914690971375\n",
            "Batch : 790, Loss : 0.5170290470123291\n",
            "Batch : 791, Loss : 0.5375247597694397\n",
            "Batch : 792, Loss : 0.6520292162895203\n",
            "Batch : 793, Loss : 0.6902981996536255\n",
            "Batch : 794, Loss : 0.8067542314529419\n",
            "Batch : 795, Loss : 0.6559126377105713\n",
            "Batch : 796, Loss : 0.6070197224617004\n",
            "Batch : 797, Loss : 0.7719954252243042\n",
            "Batch : 798, Loss : 0.6256872415542603\n",
            "Batch : 799, Loss : 0.8847061991691589\n",
            "Batch : 800, Loss : 0.47382745146751404\n",
            "Batch : 801, Loss : 0.5556889176368713\n",
            "Batch : 802, Loss : 0.8183879852294922\n",
            "Batch : 803, Loss : 0.7259058952331543\n",
            "Batch : 804, Loss : 0.7395936250686646\n",
            "Batch : 805, Loss : 0.7877678871154785\n",
            "Batch : 806, Loss : 0.8586952090263367\n",
            "Batch : 807, Loss : 0.5273937582969666\n",
            "Batch : 808, Loss : 0.655465841293335\n",
            "Batch : 809, Loss : 0.6528433561325073\n",
            "Batch : 810, Loss : 0.5450810194015503\n",
            "Batch : 811, Loss : 0.7224227786064148\n",
            "Batch : 812, Loss : 0.6799682378768921\n",
            "Batch : 813, Loss : 0.6849107146263123\n",
            "Batch : 814, Loss : 0.6917502284049988\n",
            "Batch : 815, Loss : 0.8165062665939331\n",
            "Batch : 816, Loss : 0.5341352224349976\n",
            "Batch : 817, Loss : 0.8386682271957397\n",
            "Batch : 818, Loss : 0.8520596623420715\n",
            "Batch : 819, Loss : 0.6787591576576233\n",
            "Batch : 820, Loss : 0.6230121850967407\n",
            "Batch : 821, Loss : 0.6668369770050049\n",
            "Batch : 822, Loss : 0.6922442317008972\n",
            "Batch : 823, Loss : 0.6279900670051575\n",
            "Batch : 824, Loss : 0.7132285833358765\n",
            "Batch : 825, Loss : 0.5472467541694641\n",
            "Batch : 826, Loss : 0.8614696264266968\n",
            "Batch : 827, Loss : 0.5713618397712708\n",
            "Batch : 828, Loss : 0.5583204030990601\n",
            "Batch : 829, Loss : 0.5900772213935852\n",
            "Batch : 830, Loss : 0.6408793330192566\n",
            "Batch : 831, Loss : 0.7134582996368408\n",
            "Batch : 832, Loss : 0.7274059653282166\n",
            "Batch : 833, Loss : 0.7110588550567627\n",
            "Batch : 834, Loss : 0.6180598735809326\n",
            "Batch : 835, Loss : 0.6050151586532593\n",
            "Batch : 836, Loss : 0.48032817244529724\n",
            "Batch : 837, Loss : 0.5072157382965088\n",
            "Batch : 838, Loss : 0.5924625396728516\n",
            "Batch : 839, Loss : 0.607728898525238\n",
            "Batch : 840, Loss : 0.6821167469024658\n",
            "Batch : 841, Loss : 0.6450222730636597\n",
            "Batch : 842, Loss : 0.763769268989563\n",
            "Batch : 843, Loss : 0.38847991824150085\n",
            "Batch : 844, Loss : 0.8235310912132263\n",
            "Batch : 845, Loss : 0.7360798120498657\n",
            "Batch : 846, Loss : 0.5619617700576782\n",
            "Batch : 847, Loss : 0.5440781712532043\n",
            "Batch : 848, Loss : 0.551372766494751\n",
            "Batch : 849, Loss : 0.6542181968688965\n",
            "Batch : 850, Loss : 0.5165915489196777\n",
            "Batch : 851, Loss : 0.42852261662483215\n",
            "Batch : 852, Loss : 0.5836220383644104\n",
            "Batch : 853, Loss : 0.612700343132019\n",
            "Batch : 854, Loss : 0.8291050791740417\n",
            "Batch : 855, Loss : 0.7426977753639221\n",
            "Batch : 856, Loss : 0.6088963747024536\n",
            "Batch : 857, Loss : 0.5018158555030823\n",
            "Batch : 858, Loss : 0.5401034355163574\n",
            "Batch : 859, Loss : 0.6851250529289246\n",
            "Batch : 860, Loss : 0.5616324543952942\n",
            "Batch : 861, Loss : 0.5976323485374451\n",
            "Batch : 862, Loss : 0.6349998116493225\n",
            "Batch : 863, Loss : 0.6486508846282959\n",
            "Batch : 864, Loss : 0.8011976480484009\n",
            "Batch : 865, Loss : 0.6214758157730103\n",
            "Batch : 866, Loss : 0.5801427960395813\n",
            "Batch : 867, Loss : 0.5957582592964172\n",
            "Batch : 868, Loss : 0.6155467629432678\n",
            "Batch : 869, Loss : 0.6103589534759521\n",
            "Batch : 870, Loss : 0.4534837603569031\n",
            "Batch : 871, Loss : 0.4979571998119354\n",
            "Batch : 872, Loss : 0.5454566478729248\n",
            "Batch : 873, Loss : 0.6277899742126465\n",
            "Batch : 874, Loss : 0.7150433659553528\n",
            "Batch : 875, Loss : 0.7016868591308594\n",
            "Batch : 876, Loss : 0.615485429763794\n",
            "Batch : 877, Loss : 0.6737300753593445\n",
            "Batch : 878, Loss : 0.6567582488059998\n",
            "Batch : 879, Loss : 0.4792943596839905\n",
            "Batch : 880, Loss : 0.6340863108634949\n",
            "Batch : 881, Loss : 0.6808887124061584\n",
            "Batch : 882, Loss : 0.6090980768203735\n",
            "Batch : 883, Loss : 0.7780507206916809\n",
            "Batch : 884, Loss : 0.537077784538269\n",
            "Batch : 885, Loss : 0.7619637250900269\n",
            "Batch : 886, Loss : 0.7369798421859741\n",
            "Batch : 887, Loss : 0.6695443391799927\n",
            "Batch : 888, Loss : 0.5799139142036438\n",
            "Batch : 889, Loss : 0.6244765520095825\n",
            "Batch : 890, Loss : 0.5317654609680176\n",
            "Batch : 891, Loss : 0.6085253357887268\n",
            "Batch : 892, Loss : 0.3099272847175598\n",
            "Batch : 893, Loss : 0.6244959831237793\n",
            "Batch : 894, Loss : 0.6166399121284485\n",
            "Batch : 895, Loss : 0.6421351432800293\n",
            "Batch : 896, Loss : 0.49138376116752625\n",
            "Batch : 897, Loss : 0.5514589548110962\n",
            "Batch : 898, Loss : 0.6340650916099548\n",
            "Batch : 899, Loss : 0.7303182482719421\n",
            "Batch : 900, Loss : 0.5256174802780151\n",
            "Batch : 901, Loss : 0.5838955044746399\n",
            "Batch : 902, Loss : 0.6183748841285706\n",
            "Batch : 903, Loss : 0.7108734846115112\n",
            "Batch : 904, Loss : 0.7283482551574707\n",
            "Batch : 905, Loss : 0.528496265411377\n",
            "Batch : 906, Loss : 0.5846290588378906\n",
            "Batch : 907, Loss : 0.629153847694397\n",
            "Batch : 908, Loss : 0.6800796389579773\n",
            "Batch : 909, Loss : 0.7187274694442749\n",
            "Batch : 910, Loss : 0.6455782651901245\n",
            "Batch : 911, Loss : 0.5343949794769287\n",
            "Batch : 912, Loss : 0.5923802256584167\n",
            "Batch : 913, Loss : 0.6160666942596436\n",
            "Batch : 914, Loss : 0.5296148657798767\n",
            "Batch : 915, Loss : 0.7080638408660889\n",
            "Batch : 916, Loss : 0.5140625834465027\n",
            "Batch : 917, Loss : 0.721864640712738\n",
            "Batch : 918, Loss : 0.474089115858078\n",
            "Batch : 919, Loss : 0.47423607110977173\n",
            "Batch : 920, Loss : 0.4816601276397705\n",
            "Batch : 921, Loss : 0.5074300169944763\n",
            "Batch : 922, Loss : 0.44962331652641296\n",
            "Batch : 923, Loss : 0.5409784913063049\n",
            "Batch : 924, Loss : 0.8018249869346619\n",
            "Batch : 925, Loss : 0.553347110748291\n",
            "Batch : 926, Loss : 0.662512481212616\n",
            "Batch : 927, Loss : 0.6711603403091431\n",
            "Batch : 928, Loss : 0.5060847401618958\n",
            "Batch : 929, Loss : 0.48008498549461365\n",
            "Batch : 930, Loss : 0.5144579410552979\n",
            "Batch : 931, Loss : 0.594380795955658\n",
            "Batch : 932, Loss : 0.6778182983398438\n",
            "Batch : 933, Loss : 0.5705057978630066\n",
            "Batch : 934, Loss : 0.647588312625885\n",
            "Batch : 935, Loss : 0.5638453960418701\n",
            "Batch : 936, Loss : 0.5563006401062012\n",
            "Batch : 937, Loss : 0.5517527461051941\n",
            "Batch : 938, Loss : 0.8963955640792847\n",
            "Training loss: 1.0100437694394004\n",
            "Batch : 1, Loss : 0.7538157105445862\n",
            "Batch : 2, Loss : 0.6890154480934143\n",
            "Batch : 3, Loss : 0.5057803988456726\n",
            "Batch : 4, Loss : 0.7543364763259888\n",
            "Batch : 5, Loss : 0.5557333827018738\n",
            "Batch : 6, Loss : 0.7235999703407288\n",
            "Batch : 7, Loss : 0.840890109539032\n",
            "Batch : 8, Loss : 0.6232255101203918\n",
            "Batch : 9, Loss : 0.6250711679458618\n",
            "Batch : 10, Loss : 0.3529161810874939\n",
            "Batch : 11, Loss : 0.6619813442230225\n",
            "Batch : 12, Loss : 0.715721845626831\n",
            "Batch : 13, Loss : 0.622002363204956\n",
            "Batch : 14, Loss : 0.6078035235404968\n",
            "Batch : 15, Loss : 0.4849819839000702\n",
            "Batch : 16, Loss : 0.42938706278800964\n",
            "Batch : 17, Loss : 0.4775710105895996\n",
            "Batch : 18, Loss : 0.5581023097038269\n",
            "Batch : 19, Loss : 0.6633001565933228\n",
            "Batch : 20, Loss : 0.6786113977432251\n",
            "Batch : 21, Loss : 0.7322322726249695\n",
            "Batch : 22, Loss : 0.6364873647689819\n",
            "Batch : 23, Loss : 0.7139804363250732\n",
            "Batch : 24, Loss : 0.5721132755279541\n",
            "Batch : 25, Loss : 0.61549311876297\n",
            "Batch : 26, Loss : 0.5814957022666931\n",
            "Batch : 27, Loss : 0.7043289542198181\n",
            "Batch : 28, Loss : 0.5039603114128113\n",
            "Batch : 29, Loss : 0.5247765779495239\n",
            "Batch : 30, Loss : 0.5097888708114624\n",
            "Batch : 31, Loss : 0.6207211017608643\n",
            "Batch : 32, Loss : 0.6338056325912476\n",
            "Batch : 33, Loss : 0.8098506927490234\n",
            "Batch : 34, Loss : 0.5889073610305786\n",
            "Batch : 35, Loss : 0.608959972858429\n",
            "Batch : 36, Loss : 0.730351984500885\n",
            "Batch : 37, Loss : 0.704889178276062\n",
            "Batch : 38, Loss : 0.6213062405586243\n",
            "Batch : 39, Loss : 0.5301913022994995\n",
            "Batch : 40, Loss : 0.5466156601905823\n",
            "Batch : 41, Loss : 0.5268821716308594\n",
            "Batch : 42, Loss : 0.7637553811073303\n",
            "Batch : 43, Loss : 0.5156777501106262\n",
            "Batch : 44, Loss : 0.5257489085197449\n",
            "Batch : 45, Loss : 0.4741627871990204\n",
            "Batch : 46, Loss : 0.7620235085487366\n",
            "Batch : 47, Loss : 0.4827779233455658\n",
            "Batch : 48, Loss : 0.6073324084281921\n",
            "Batch : 49, Loss : 0.463334321975708\n",
            "Batch : 50, Loss : 0.6111083030700684\n",
            "Batch : 51, Loss : 0.557084858417511\n",
            "Batch : 52, Loss : 0.5820524096488953\n",
            "Batch : 53, Loss : 0.6853236556053162\n",
            "Batch : 54, Loss : 0.5658599138259888\n",
            "Batch : 55, Loss : 0.592822790145874\n",
            "Batch : 56, Loss : 0.5670158863067627\n",
            "Batch : 57, Loss : 0.7017338871955872\n",
            "Batch : 58, Loss : 0.6254633665084839\n",
            "Batch : 59, Loss : 0.5798810720443726\n",
            "Batch : 60, Loss : 0.5714036822319031\n",
            "Batch : 61, Loss : 0.453365683555603\n",
            "Batch : 62, Loss : 0.6044089198112488\n",
            "Batch : 63, Loss : 0.659078061580658\n",
            "Batch : 64, Loss : 0.48749086260795593\n",
            "Batch : 65, Loss : 0.5316572189331055\n",
            "Batch : 66, Loss : 0.5582852959632874\n",
            "Batch : 67, Loss : 0.6119481921195984\n",
            "Batch : 68, Loss : 0.5817773342132568\n",
            "Batch : 69, Loss : 0.7140620946884155\n",
            "Batch : 70, Loss : 0.8492239117622375\n",
            "Batch : 71, Loss : 0.5173985958099365\n",
            "Batch : 72, Loss : 0.6704825162887573\n",
            "Batch : 73, Loss : 0.76783287525177\n",
            "Batch : 74, Loss : 0.5563976764678955\n",
            "Batch : 75, Loss : 0.6503115296363831\n",
            "Batch : 76, Loss : 0.49310529232025146\n",
            "Batch : 77, Loss : 0.4575354754924774\n",
            "Batch : 78, Loss : 0.6862856149673462\n",
            "Batch : 79, Loss : 0.5506282448768616\n",
            "Batch : 80, Loss : 0.617793619632721\n",
            "Batch : 81, Loss : 0.47198617458343506\n",
            "Batch : 82, Loss : 0.6295667886734009\n",
            "Batch : 83, Loss : 0.49450352787971497\n",
            "Batch : 84, Loss : 0.5597718954086304\n",
            "Batch : 85, Loss : 0.589972198009491\n",
            "Batch : 86, Loss : 0.823894202709198\n",
            "Batch : 87, Loss : 0.6015751957893372\n",
            "Batch : 88, Loss : 0.604845404624939\n",
            "Batch : 89, Loss : 0.6429213881492615\n",
            "Batch : 90, Loss : 0.6134195327758789\n",
            "Batch : 91, Loss : 0.6172757148742676\n",
            "Batch : 92, Loss : 0.5883578658103943\n",
            "Batch : 93, Loss : 0.5847848057746887\n",
            "Batch : 94, Loss : 0.5109609365463257\n",
            "Batch : 95, Loss : 0.7829586863517761\n",
            "Batch : 96, Loss : 0.6813616752624512\n",
            "Batch : 97, Loss : 0.5376957058906555\n",
            "Batch : 98, Loss : 0.5928263068199158\n",
            "Batch : 99, Loss : 0.6096419095993042\n",
            "Batch : 100, Loss : 0.46254342794418335\n",
            "Batch : 101, Loss : 0.6551643013954163\n",
            "Batch : 102, Loss : 0.5077206492424011\n",
            "Batch : 103, Loss : 0.6776084899902344\n",
            "Batch : 104, Loss : 0.6184110045433044\n",
            "Batch : 105, Loss : 0.542261004447937\n",
            "Batch : 106, Loss : 0.6412231922149658\n",
            "Batch : 107, Loss : 0.46261781454086304\n",
            "Batch : 108, Loss : 0.489982008934021\n",
            "Batch : 109, Loss : 0.6578730344772339\n",
            "Batch : 110, Loss : 0.6220444440841675\n",
            "Batch : 111, Loss : 0.4779653549194336\n",
            "Batch : 112, Loss : 0.7472218871116638\n",
            "Batch : 113, Loss : 0.47978436946868896\n",
            "Batch : 114, Loss : 0.5023795366287231\n",
            "Batch : 115, Loss : 0.4485948383808136\n",
            "Batch : 116, Loss : 0.6505921483039856\n",
            "Batch : 117, Loss : 0.4549466073513031\n",
            "Batch : 118, Loss : 0.476136177778244\n",
            "Batch : 119, Loss : 0.7085793614387512\n",
            "Batch : 120, Loss : 0.635778546333313\n",
            "Batch : 121, Loss : 0.7173853516578674\n",
            "Batch : 122, Loss : 0.683217465877533\n",
            "Batch : 123, Loss : 0.5695365071296692\n",
            "Batch : 124, Loss : 0.5127881765365601\n",
            "Batch : 125, Loss : 0.6190934181213379\n",
            "Batch : 126, Loss : 0.41753509640693665\n",
            "Batch : 127, Loss : 0.8133751749992371\n",
            "Batch : 128, Loss : 0.6010642051696777\n",
            "Batch : 129, Loss : 0.767986536026001\n",
            "Batch : 130, Loss : 0.4576721787452698\n",
            "Batch : 131, Loss : 0.6512721180915833\n",
            "Batch : 132, Loss : 0.5938411355018616\n",
            "Batch : 133, Loss : 0.7441102266311646\n",
            "Batch : 134, Loss : 0.6701959371566772\n",
            "Batch : 135, Loss : 0.5659359097480774\n",
            "Batch : 136, Loss : 0.6101760268211365\n",
            "Batch : 137, Loss : 0.4516063332557678\n",
            "Batch : 138, Loss : 0.5824489593505859\n",
            "Batch : 139, Loss : 0.711837649345398\n",
            "Batch : 140, Loss : 0.6698300838470459\n",
            "Batch : 141, Loss : 0.5499362945556641\n",
            "Batch : 142, Loss : 0.5298712849617004\n",
            "Batch : 143, Loss : 0.41226139664649963\n",
            "Batch : 144, Loss : 0.500619649887085\n",
            "Batch : 145, Loss : 0.49594300985336304\n",
            "Batch : 146, Loss : 0.613161563873291\n",
            "Batch : 147, Loss : 0.6903207898139954\n",
            "Batch : 148, Loss : 0.5469586849212646\n",
            "Batch : 149, Loss : 0.46775785088539124\n",
            "Batch : 150, Loss : 0.4789254069328308\n",
            "Batch : 151, Loss : 0.6393652558326721\n",
            "Batch : 152, Loss : 0.5699811577796936\n",
            "Batch : 153, Loss : 0.6388936638832092\n",
            "Batch : 154, Loss : 0.5092360377311707\n",
            "Batch : 155, Loss : 0.6175666451454163\n",
            "Batch : 156, Loss : 0.5381343364715576\n",
            "Batch : 157, Loss : 0.8575245141983032\n",
            "Batch : 158, Loss : 0.7019597291946411\n",
            "Batch : 159, Loss : 0.5669194459915161\n",
            "Batch : 160, Loss : 0.5748912692070007\n",
            "Batch : 161, Loss : 0.6562045812606812\n",
            "Batch : 162, Loss : 0.6242168545722961\n",
            "Batch : 163, Loss : 0.5741932988166809\n",
            "Batch : 164, Loss : 0.704563558101654\n",
            "Batch : 165, Loss : 0.42694640159606934\n",
            "Batch : 166, Loss : 0.6459224224090576\n",
            "Batch : 167, Loss : 0.5514642596244812\n",
            "Batch : 168, Loss : 0.7854553461074829\n",
            "Batch : 169, Loss : 0.7022591233253479\n",
            "Batch : 170, Loss : 0.7630122303962708\n",
            "Batch : 171, Loss : 0.5123281478881836\n",
            "Batch : 172, Loss : 0.5554676651954651\n",
            "Batch : 173, Loss : 0.6361210942268372\n",
            "Batch : 174, Loss : 0.7188535332679749\n",
            "Batch : 175, Loss : 0.7025495767593384\n",
            "Batch : 176, Loss : 0.8199931979179382\n",
            "Batch : 177, Loss : 0.5620265007019043\n",
            "Batch : 178, Loss : 0.7800319194793701\n",
            "Batch : 179, Loss : 0.6971307396888733\n",
            "Batch : 180, Loss : 0.7582809329032898\n",
            "Batch : 181, Loss : 0.4996529519557953\n",
            "Batch : 182, Loss : 0.7444733381271362\n",
            "Batch : 183, Loss : 0.7615547180175781\n",
            "Batch : 184, Loss : 0.5889046788215637\n",
            "Batch : 185, Loss : 0.501031219959259\n",
            "Batch : 186, Loss : 0.4556632339954376\n",
            "Batch : 187, Loss : 0.6630391478538513\n",
            "Batch : 188, Loss : 0.5675915479660034\n",
            "Batch : 189, Loss : 0.4837093651294708\n",
            "Batch : 190, Loss : 0.7292047142982483\n",
            "Batch : 191, Loss : 0.6798955202102661\n",
            "Batch : 192, Loss : 0.6460860371589661\n",
            "Batch : 193, Loss : 0.5836991667747498\n",
            "Batch : 194, Loss : 0.6300176382064819\n",
            "Batch : 195, Loss : 0.6210066676139832\n",
            "Batch : 196, Loss : 0.6392953991889954\n",
            "Batch : 197, Loss : 0.610492467880249\n",
            "Batch : 198, Loss : 0.6523904800415039\n",
            "Batch : 199, Loss : 0.5653595328330994\n",
            "Batch : 200, Loss : 0.5017039179801941\n",
            "Batch : 201, Loss : 0.6340075731277466\n",
            "Batch : 202, Loss : 0.6996079087257385\n",
            "Batch : 203, Loss : 0.5395089387893677\n",
            "Batch : 204, Loss : 0.5268170237541199\n",
            "Batch : 205, Loss : 0.5167897939682007\n",
            "Batch : 206, Loss : 0.6195741295814514\n",
            "Batch : 207, Loss : 0.6441720128059387\n",
            "Batch : 208, Loss : 0.5767419934272766\n",
            "Batch : 209, Loss : 0.5442237854003906\n",
            "Batch : 210, Loss : 0.6394592523574829\n",
            "Batch : 211, Loss : 0.4643069803714752\n",
            "Batch : 212, Loss : 0.45013734698295593\n",
            "Batch : 213, Loss : 0.8357980251312256\n",
            "Batch : 214, Loss : 0.5454784035682678\n",
            "Batch : 215, Loss : 0.6939210891723633\n",
            "Batch : 216, Loss : 0.3976913094520569\n",
            "Batch : 217, Loss : 0.5355027318000793\n",
            "Batch : 218, Loss : 0.5573123097419739\n",
            "Batch : 219, Loss : 0.5812584757804871\n",
            "Batch : 220, Loss : 0.6287447214126587\n",
            "Batch : 221, Loss : 0.6033534407615662\n",
            "Batch : 222, Loss : 0.44201406836509705\n",
            "Batch : 223, Loss : 0.6357919573783875\n",
            "Batch : 224, Loss : 0.5912681818008423\n",
            "Batch : 225, Loss : 0.5642865896224976\n",
            "Batch : 226, Loss : 0.37290576100349426\n",
            "Batch : 227, Loss : 0.5616997480392456\n",
            "Batch : 228, Loss : 0.7092044353485107\n",
            "Batch : 229, Loss : 0.5279404520988464\n",
            "Batch : 230, Loss : 0.5754164457321167\n",
            "Batch : 231, Loss : 0.5556865334510803\n",
            "Batch : 232, Loss : 0.4913201928138733\n",
            "Batch : 233, Loss : 0.5233451724052429\n",
            "Batch : 234, Loss : 0.4752734899520874\n",
            "Batch : 235, Loss : 0.7813124060630798\n",
            "Batch : 236, Loss : 0.8103523254394531\n",
            "Batch : 237, Loss : 0.7265489101409912\n",
            "Batch : 238, Loss : 0.5353468060493469\n",
            "Batch : 239, Loss : 0.47385886311531067\n",
            "Batch : 240, Loss : 0.6221178770065308\n",
            "Batch : 241, Loss : 0.6883248686790466\n",
            "Batch : 242, Loss : 0.5699208378791809\n",
            "Batch : 243, Loss : 0.5975009202957153\n",
            "Batch : 244, Loss : 0.8211628794670105\n",
            "Batch : 245, Loss : 0.5949090719223022\n",
            "Batch : 246, Loss : 0.4589598476886749\n",
            "Batch : 247, Loss : 0.8556286096572876\n",
            "Batch : 248, Loss : 0.6121340990066528\n",
            "Batch : 249, Loss : 0.5306621789932251\n",
            "Batch : 250, Loss : 0.6318599581718445\n",
            "Batch : 251, Loss : 0.7230474352836609\n",
            "Batch : 252, Loss : 0.5940906405448914\n",
            "Batch : 253, Loss : 0.5198389291763306\n",
            "Batch : 254, Loss : 0.5282630324363708\n",
            "Batch : 255, Loss : 0.7213024497032166\n",
            "Batch : 256, Loss : 0.5694352388381958\n",
            "Batch : 257, Loss : 0.7581822276115417\n",
            "Batch : 258, Loss : 0.6921807527542114\n",
            "Batch : 259, Loss : 0.48989301919937134\n",
            "Batch : 260, Loss : 0.5861262083053589\n",
            "Batch : 261, Loss : 0.5481359362602234\n",
            "Batch : 262, Loss : 0.5923221111297607\n",
            "Batch : 263, Loss : 0.5588087439537048\n",
            "Batch : 264, Loss : 0.5467549562454224\n",
            "Batch : 265, Loss : 0.6531730890274048\n",
            "Batch : 266, Loss : 0.5285021066665649\n",
            "Batch : 267, Loss : 0.30837443470954895\n",
            "Batch : 268, Loss : 0.4570935070514679\n",
            "Batch : 269, Loss : 0.7252353429794312\n",
            "Batch : 270, Loss : 0.7070731520652771\n",
            "Batch : 271, Loss : 0.5971801280975342\n",
            "Batch : 272, Loss : 0.610096275806427\n",
            "Batch : 273, Loss : 0.554959774017334\n",
            "Batch : 274, Loss : 0.5545657277107239\n",
            "Batch : 275, Loss : 0.4401867687702179\n",
            "Batch : 276, Loss : 0.5354333519935608\n",
            "Batch : 277, Loss : 0.5096997022628784\n",
            "Batch : 278, Loss : 0.5473217368125916\n",
            "Batch : 279, Loss : 0.5701068043708801\n",
            "Batch : 280, Loss : 0.4191220998764038\n",
            "Batch : 281, Loss : 0.5955310463905334\n",
            "Batch : 282, Loss : 0.5035184025764465\n",
            "Batch : 283, Loss : 0.537127673625946\n",
            "Batch : 284, Loss : 0.5100377798080444\n",
            "Batch : 285, Loss : 0.48741376399993896\n",
            "Batch : 286, Loss : 0.44033941626548767\n",
            "Batch : 287, Loss : 0.6633891463279724\n",
            "Batch : 288, Loss : 0.4351246953010559\n",
            "Batch : 289, Loss : 0.5809309482574463\n",
            "Batch : 290, Loss : 0.6275322437286377\n",
            "Batch : 291, Loss : 0.5301753878593445\n",
            "Batch : 292, Loss : 0.5114002227783203\n",
            "Batch : 293, Loss : 0.48763307929039\n",
            "Batch : 294, Loss : 0.6239171028137207\n",
            "Batch : 295, Loss : 0.5159420371055603\n",
            "Batch : 296, Loss : 0.643971860408783\n",
            "Batch : 297, Loss : 0.5382840633392334\n",
            "Batch : 298, Loss : 0.5384865999221802\n",
            "Batch : 299, Loss : 0.5669366121292114\n",
            "Batch : 300, Loss : 0.45978713035583496\n",
            "Batch : 301, Loss : 0.7988741993904114\n",
            "Batch : 302, Loss : 0.6219775080680847\n",
            "Batch : 303, Loss : 0.6627762913703918\n",
            "Batch : 304, Loss : 0.7323775887489319\n",
            "Batch : 305, Loss : 0.4938836693763733\n",
            "Batch : 306, Loss : 0.5751068592071533\n",
            "Batch : 307, Loss : 0.5084292888641357\n",
            "Batch : 308, Loss : 0.6893605589866638\n",
            "Batch : 309, Loss : 0.35776060819625854\n",
            "Batch : 310, Loss : 0.5602346062660217\n",
            "Batch : 311, Loss : 0.6814882159233093\n",
            "Batch : 312, Loss : 0.5695509910583496\n",
            "Batch : 313, Loss : 0.719155490398407\n",
            "Batch : 314, Loss : 0.5325296521186829\n",
            "Batch : 315, Loss : 0.528494119644165\n",
            "Batch : 316, Loss : 0.4895671308040619\n",
            "Batch : 317, Loss : 0.5240498781204224\n",
            "Batch : 318, Loss : 0.512819766998291\n",
            "Batch : 319, Loss : 0.4452292323112488\n",
            "Batch : 320, Loss : 0.597975492477417\n",
            "Batch : 321, Loss : 0.5604936480522156\n",
            "Batch : 322, Loss : 0.5949864387512207\n",
            "Batch : 323, Loss : 0.5532876253128052\n",
            "Batch : 324, Loss : 0.5929169058799744\n",
            "Batch : 325, Loss : 0.44922322034835815\n",
            "Batch : 326, Loss : 0.43677762150764465\n",
            "Batch : 327, Loss : 0.5579036474227905\n",
            "Batch : 328, Loss : 0.3884708285331726\n",
            "Batch : 329, Loss : 0.6000886559486389\n",
            "Batch : 330, Loss : 0.5641022324562073\n",
            "Batch : 331, Loss : 0.632728636264801\n",
            "Batch : 332, Loss : 0.6081787943840027\n",
            "Batch : 333, Loss : 0.6311569213867188\n",
            "Batch : 334, Loss : 0.6025956869125366\n",
            "Batch : 335, Loss : 0.5563620328903198\n",
            "Batch : 336, Loss : 0.5460651516914368\n",
            "Batch : 337, Loss : 0.740217387676239\n",
            "Batch : 338, Loss : 0.7036057114601135\n",
            "Batch : 339, Loss : 0.7748216390609741\n",
            "Batch : 340, Loss : 0.6279078722000122\n",
            "Batch : 341, Loss : 0.6116844415664673\n",
            "Batch : 342, Loss : 0.4789992570877075\n",
            "Batch : 343, Loss : 0.403053343296051\n",
            "Batch : 344, Loss : 0.567379355430603\n",
            "Batch : 345, Loss : 0.511326253414154\n",
            "Batch : 346, Loss : 0.4613596498966217\n",
            "Batch : 347, Loss : 0.6805998682975769\n",
            "Batch : 348, Loss : 0.6472845673561096\n",
            "Batch : 349, Loss : 0.45647552609443665\n",
            "Batch : 350, Loss : 0.6857936382293701\n",
            "Batch : 351, Loss : 0.6337141394615173\n",
            "Batch : 352, Loss : 0.5247642397880554\n",
            "Batch : 353, Loss : 0.487278014421463\n",
            "Batch : 354, Loss : 0.5241649746894836\n",
            "Batch : 355, Loss : 0.5490216612815857\n",
            "Batch : 356, Loss : 0.7623758316040039\n",
            "Batch : 357, Loss : 0.6785962581634521\n",
            "Batch : 358, Loss : 0.44422444701194763\n",
            "Batch : 359, Loss : 0.6101104021072388\n",
            "Batch : 360, Loss : 0.6439366340637207\n",
            "Batch : 361, Loss : 0.5683160424232483\n",
            "Batch : 362, Loss : 0.350392609834671\n",
            "Batch : 363, Loss : 0.5344074964523315\n",
            "Batch : 364, Loss : 0.5714725255966187\n",
            "Batch : 365, Loss : 0.4779094457626343\n",
            "Batch : 366, Loss : 0.5476560592651367\n",
            "Batch : 367, Loss : 0.44244226813316345\n",
            "Batch : 368, Loss : 0.6197787523269653\n",
            "Batch : 369, Loss : 0.5951802134513855\n",
            "Batch : 370, Loss : 0.6364403963088989\n",
            "Batch : 371, Loss : 0.49340859055519104\n",
            "Batch : 372, Loss : 0.5236387252807617\n",
            "Batch : 373, Loss : 0.6897977590560913\n",
            "Batch : 374, Loss : 0.5670101046562195\n",
            "Batch : 375, Loss : 0.5592284798622131\n",
            "Batch : 376, Loss : 0.5002713203430176\n",
            "Batch : 377, Loss : 0.39397796988487244\n",
            "Batch : 378, Loss : 0.6034678220748901\n",
            "Batch : 379, Loss : 0.545182466506958\n",
            "Batch : 380, Loss : 0.6131583452224731\n",
            "Batch : 381, Loss : 0.5850653052330017\n",
            "Batch : 382, Loss : 0.535186767578125\n",
            "Batch : 383, Loss : 0.440432608127594\n",
            "Batch : 384, Loss : 0.4884629249572754\n",
            "Batch : 385, Loss : 0.6527572274208069\n",
            "Batch : 386, Loss : 0.3880198001861572\n",
            "Batch : 387, Loss : 0.6491056084632874\n",
            "Batch : 388, Loss : 0.5691564679145813\n",
            "Batch : 389, Loss : 0.4908386170864105\n",
            "Batch : 390, Loss : 0.43885037302970886\n",
            "Batch : 391, Loss : 0.5337092280387878\n",
            "Batch : 392, Loss : 0.41062840819358826\n",
            "Batch : 393, Loss : 0.49695226550102234\n",
            "Batch : 394, Loss : 0.7108363509178162\n",
            "Batch : 395, Loss : 0.6880661249160767\n",
            "Batch : 396, Loss : 0.5904342532157898\n",
            "Batch : 397, Loss : 0.5315973162651062\n",
            "Batch : 398, Loss : 0.5715098977088928\n",
            "Batch : 399, Loss : 0.6616568565368652\n",
            "Batch : 400, Loss : 0.4359050691127777\n",
            "Batch : 401, Loss : 0.5395182967185974\n",
            "Batch : 402, Loss : 0.5844332575798035\n",
            "Batch : 403, Loss : 0.6098250150680542\n",
            "Batch : 404, Loss : 0.7133105397224426\n",
            "Batch : 405, Loss : 0.5713814496994019\n",
            "Batch : 406, Loss : 0.6265488266944885\n",
            "Batch : 407, Loss : 0.5526525974273682\n",
            "Batch : 408, Loss : 0.6043550372123718\n",
            "Batch : 409, Loss : 0.6336629986763\n",
            "Batch : 410, Loss : 0.6264743208885193\n",
            "Batch : 411, Loss : 0.5067134499549866\n",
            "Batch : 412, Loss : 0.48499614000320435\n",
            "Batch : 413, Loss : 0.5524613857269287\n",
            "Batch : 414, Loss : 0.3950596749782562\n",
            "Batch : 415, Loss : 0.6299773454666138\n",
            "Batch : 416, Loss : 0.6681488156318665\n",
            "Batch : 417, Loss : 0.49385106563568115\n",
            "Batch : 418, Loss : 0.5387411713600159\n",
            "Batch : 419, Loss : 0.6694728136062622\n",
            "Batch : 420, Loss : 0.6514847874641418\n",
            "Batch : 421, Loss : 0.5415708422660828\n",
            "Batch : 422, Loss : 0.5939677357673645\n",
            "Batch : 423, Loss : 0.5216137170791626\n",
            "Batch : 424, Loss : 0.6166665554046631\n",
            "Batch : 425, Loss : 0.5016536116600037\n",
            "Batch : 426, Loss : 0.5021123290061951\n",
            "Batch : 427, Loss : 0.585743248462677\n",
            "Batch : 428, Loss : 0.5820133686065674\n",
            "Batch : 429, Loss : 0.5792722105979919\n",
            "Batch : 430, Loss : 0.5657151341438293\n",
            "Batch : 431, Loss : 0.7710036039352417\n",
            "Batch : 432, Loss : 0.4823538064956665\n",
            "Batch : 433, Loss : 0.6130409240722656\n",
            "Batch : 434, Loss : 0.5886427164077759\n",
            "Batch : 435, Loss : 0.5840995907783508\n",
            "Batch : 436, Loss : 0.5125805735588074\n",
            "Batch : 437, Loss : 0.5669670104980469\n",
            "Batch : 438, Loss : 0.7113180160522461\n",
            "Batch : 439, Loss : 0.5314505100250244\n",
            "Batch : 440, Loss : 0.5257740020751953\n",
            "Batch : 441, Loss : 0.5724138021469116\n",
            "Batch : 442, Loss : 0.5193771719932556\n",
            "Batch : 443, Loss : 0.48552438616752625\n",
            "Batch : 444, Loss : 0.5260365009307861\n",
            "Batch : 445, Loss : 0.6385959982872009\n",
            "Batch : 446, Loss : 0.6046401858329773\n",
            "Batch : 447, Loss : 0.6442413330078125\n",
            "Batch : 448, Loss : 0.6819763779640198\n",
            "Batch : 449, Loss : 0.5517476201057434\n",
            "Batch : 450, Loss : 0.5972877740859985\n",
            "Batch : 451, Loss : 0.696415901184082\n",
            "Batch : 452, Loss : 0.43220019340515137\n",
            "Batch : 453, Loss : 0.5035785436630249\n",
            "Batch : 454, Loss : 0.5200862288475037\n",
            "Batch : 455, Loss : 0.5801411867141724\n",
            "Batch : 456, Loss : 0.5580428838729858\n",
            "Batch : 457, Loss : 0.5894883871078491\n",
            "Batch : 458, Loss : 0.4333452582359314\n",
            "Batch : 459, Loss : 0.5034131407737732\n",
            "Batch : 460, Loss : 0.575559139251709\n",
            "Batch : 461, Loss : 0.6929624676704407\n",
            "Batch : 462, Loss : 0.5735766887664795\n",
            "Batch : 463, Loss : 0.5175482034683228\n",
            "Batch : 464, Loss : 0.5185387134552002\n",
            "Batch : 465, Loss : 0.5910422205924988\n",
            "Batch : 466, Loss : 0.6954164505004883\n",
            "Batch : 467, Loss : 0.6038423180580139\n",
            "Batch : 468, Loss : 0.6642099618911743\n",
            "Batch : 469, Loss : 0.48110315203666687\n",
            "Batch : 470, Loss : 0.5322822332382202\n",
            "Batch : 471, Loss : 0.6063525676727295\n",
            "Batch : 472, Loss : 0.5265730619430542\n",
            "Batch : 473, Loss : 0.6400195956230164\n",
            "Batch : 474, Loss : 0.6082207560539246\n",
            "Batch : 475, Loss : 0.6086826324462891\n",
            "Batch : 476, Loss : 0.5558626055717468\n",
            "Batch : 477, Loss : 0.535696268081665\n",
            "Batch : 478, Loss : 0.5684288740158081\n",
            "Batch : 479, Loss : 0.5111221075057983\n",
            "Batch : 480, Loss : 0.6679746508598328\n",
            "Batch : 481, Loss : 0.47036829590797424\n",
            "Batch : 482, Loss : 0.500478982925415\n",
            "Batch : 483, Loss : 0.5076326727867126\n",
            "Batch : 484, Loss : 0.5680078268051147\n",
            "Batch : 485, Loss : 0.5169572234153748\n",
            "Batch : 486, Loss : 0.5498535633087158\n",
            "Batch : 487, Loss : 0.5079121589660645\n",
            "Batch : 488, Loss : 0.5497437715530396\n",
            "Batch : 489, Loss : 0.5194514393806458\n",
            "Batch : 490, Loss : 0.6197500228881836\n",
            "Batch : 491, Loss : 0.550480306148529\n",
            "Batch : 492, Loss : 0.7090878486633301\n",
            "Batch : 493, Loss : 0.5851936936378479\n",
            "Batch : 494, Loss : 0.4580601751804352\n",
            "Batch : 495, Loss : 0.5852364301681519\n",
            "Batch : 496, Loss : 0.4161568284034729\n",
            "Batch : 497, Loss : 0.5906769037246704\n",
            "Batch : 498, Loss : 0.37446296215057373\n",
            "Batch : 499, Loss : 0.6774005889892578\n",
            "Batch : 500, Loss : 0.5906665325164795\n",
            "Batch : 501, Loss : 0.45558086037635803\n",
            "Batch : 502, Loss : 0.3528284728527069\n",
            "Batch : 503, Loss : 0.5682490468025208\n",
            "Batch : 504, Loss : 0.4668818414211273\n",
            "Batch : 505, Loss : 0.6387563943862915\n",
            "Batch : 506, Loss : 0.35669058561325073\n",
            "Batch : 507, Loss : 0.5456851124763489\n",
            "Batch : 508, Loss : 0.7850621938705444\n",
            "Batch : 509, Loss : 0.48757070302963257\n",
            "Batch : 510, Loss : 0.5144854784011841\n",
            "Batch : 511, Loss : 0.705125093460083\n",
            "Batch : 512, Loss : 0.49688297510147095\n",
            "Batch : 513, Loss : 0.5274306535720825\n",
            "Batch : 514, Loss : 0.6222437024116516\n",
            "Batch : 515, Loss : 0.697491466999054\n",
            "Batch : 516, Loss : 0.3842916190624237\n",
            "Batch : 517, Loss : 0.5028590559959412\n",
            "Batch : 518, Loss : 0.55760258436203\n",
            "Batch : 519, Loss : 0.468899667263031\n",
            "Batch : 520, Loss : 0.5048855543136597\n",
            "Batch : 521, Loss : 0.3848346173763275\n",
            "Batch : 522, Loss : 0.3688614070415497\n",
            "Batch : 523, Loss : 0.5299522876739502\n",
            "Batch : 524, Loss : 0.7596698999404907\n",
            "Batch : 525, Loss : 0.5450850129127502\n",
            "Batch : 526, Loss : 0.5203078389167786\n",
            "Batch : 527, Loss : 0.5646913647651672\n",
            "Batch : 528, Loss : 0.5869733095169067\n",
            "Batch : 529, Loss : 0.4877367317676544\n",
            "Batch : 530, Loss : 0.5454883575439453\n",
            "Batch : 531, Loss : 0.5495767593383789\n",
            "Batch : 532, Loss : 0.6752775311470032\n",
            "Batch : 533, Loss : 0.46994227170944214\n",
            "Batch : 534, Loss : 0.5945984721183777\n",
            "Batch : 535, Loss : 0.49843114614486694\n",
            "Batch : 536, Loss : 0.6049765348434448\n",
            "Batch : 537, Loss : 0.5385768413543701\n",
            "Batch : 538, Loss : 0.4996658265590668\n",
            "Batch : 539, Loss : 0.519655168056488\n",
            "Batch : 540, Loss : 0.6637334823608398\n",
            "Batch : 541, Loss : 0.3961837887763977\n",
            "Batch : 542, Loss : 0.5777161717414856\n",
            "Batch : 543, Loss : 0.4168327748775482\n",
            "Batch : 544, Loss : 0.44443780183792114\n",
            "Batch : 545, Loss : 0.4598120450973511\n",
            "Batch : 546, Loss : 0.47782981395721436\n",
            "Batch : 547, Loss : 0.6245085597038269\n",
            "Batch : 548, Loss : 0.6212276816368103\n",
            "Batch : 549, Loss : 0.5333546996116638\n",
            "Batch : 550, Loss : 0.7498277425765991\n",
            "Batch : 551, Loss : 0.6680752635002136\n",
            "Batch : 552, Loss : 0.43486344814300537\n",
            "Batch : 553, Loss : 0.5394686460494995\n",
            "Batch : 554, Loss : 0.42284759879112244\n",
            "Batch : 555, Loss : 0.6025229096412659\n",
            "Batch : 556, Loss : 0.7535390853881836\n",
            "Batch : 557, Loss : 0.5467444062232971\n",
            "Batch : 558, Loss : 0.6742220520973206\n",
            "Batch : 559, Loss : 0.4888586401939392\n",
            "Batch : 560, Loss : 0.5876404047012329\n",
            "Batch : 561, Loss : 0.6468526124954224\n",
            "Batch : 562, Loss : 0.43959200382232666\n",
            "Batch : 563, Loss : 0.49915623664855957\n",
            "Batch : 564, Loss : 0.7353453636169434\n",
            "Batch : 565, Loss : 0.4772919714450836\n",
            "Batch : 566, Loss : 0.4956406056880951\n",
            "Batch : 567, Loss : 0.4941965341567993\n",
            "Batch : 568, Loss : 0.4843887388706207\n",
            "Batch : 569, Loss : 0.4969336986541748\n",
            "Batch : 570, Loss : 0.6059588193893433\n",
            "Batch : 571, Loss : 0.44052764773368835\n",
            "Batch : 572, Loss : 0.4127868413925171\n",
            "Batch : 573, Loss : 0.5480597615242004\n",
            "Batch : 574, Loss : 0.36256980895996094\n",
            "Batch : 575, Loss : 0.6493103504180908\n",
            "Batch : 576, Loss : 0.6025803089141846\n",
            "Batch : 577, Loss : 0.6854283809661865\n",
            "Batch : 578, Loss : 0.7293282747268677\n",
            "Batch : 579, Loss : 0.5940436720848083\n",
            "Batch : 580, Loss : 0.4324221611022949\n",
            "Batch : 581, Loss : 0.5551158785820007\n",
            "Batch : 582, Loss : 0.5130282640457153\n",
            "Batch : 583, Loss : 0.4723282754421234\n",
            "Batch : 584, Loss : 0.47544291615486145\n",
            "Batch : 585, Loss : 0.5016578435897827\n",
            "Batch : 586, Loss : 0.6058154106140137\n",
            "Batch : 587, Loss : 0.7141835689544678\n",
            "Batch : 588, Loss : 0.515041172504425\n",
            "Batch : 589, Loss : 0.4184815585613251\n",
            "Batch : 590, Loss : 0.5203083157539368\n",
            "Batch : 591, Loss : 0.37132778763771057\n",
            "Batch : 592, Loss : 0.4511466920375824\n",
            "Batch : 593, Loss : 0.48286980390548706\n",
            "Batch : 594, Loss : 0.5446613430976868\n",
            "Batch : 595, Loss : 0.540798544883728\n",
            "Batch : 596, Loss : 0.5429532527923584\n",
            "Batch : 597, Loss : 0.5964434146881104\n",
            "Batch : 598, Loss : 0.48510226607322693\n",
            "Batch : 599, Loss : 0.43654942512512207\n",
            "Batch : 600, Loss : 0.4817274808883667\n",
            "Batch : 601, Loss : 0.655032217502594\n",
            "Batch : 602, Loss : 0.7233982682228088\n",
            "Batch : 603, Loss : 0.5305882692337036\n",
            "Batch : 604, Loss : 0.44209155440330505\n",
            "Batch : 605, Loss : 0.674310028553009\n",
            "Batch : 606, Loss : 0.6245111227035522\n",
            "Batch : 607, Loss : 0.8471325039863586\n",
            "Batch : 608, Loss : 0.71393221616745\n",
            "Batch : 609, Loss : 0.4674625098705292\n",
            "Batch : 610, Loss : 0.5027390718460083\n",
            "Batch : 611, Loss : 0.44768062233924866\n",
            "Batch : 612, Loss : 0.6884316205978394\n",
            "Batch : 613, Loss : 0.5185769200325012\n",
            "Batch : 614, Loss : 0.5028970837593079\n",
            "Batch : 615, Loss : 0.46739259362220764\n",
            "Batch : 616, Loss : 0.6556628346443176\n",
            "Batch : 617, Loss : 0.6628345251083374\n",
            "Batch : 618, Loss : 0.5642708539962769\n",
            "Batch : 619, Loss : 0.5835629105567932\n",
            "Batch : 620, Loss : 0.3867625892162323\n",
            "Batch : 621, Loss : 0.4029006063938141\n",
            "Batch : 622, Loss : 0.5686898231506348\n",
            "Batch : 623, Loss : 0.5798628330230713\n",
            "Batch : 624, Loss : 0.5466310381889343\n",
            "Batch : 625, Loss : 0.46805208921432495\n",
            "Batch : 626, Loss : 0.7080377340316772\n",
            "Batch : 627, Loss : 0.5360760688781738\n",
            "Batch : 628, Loss : 0.5036368370056152\n",
            "Batch : 629, Loss : 0.8196200728416443\n",
            "Batch : 630, Loss : 0.5674343705177307\n",
            "Batch : 631, Loss : 0.5761827230453491\n",
            "Batch : 632, Loss : 0.7541934251785278\n",
            "Batch : 633, Loss : 0.5955336689949036\n",
            "Batch : 634, Loss : 0.6561604738235474\n",
            "Batch : 635, Loss : 0.5359635949134827\n",
            "Batch : 636, Loss : 0.5228413343429565\n",
            "Batch : 637, Loss : 0.620647132396698\n",
            "Batch : 638, Loss : 0.4225437641143799\n",
            "Batch : 639, Loss : 0.5684933066368103\n",
            "Batch : 640, Loss : 0.337619811296463\n",
            "Batch : 641, Loss : 0.6096518635749817\n",
            "Batch : 642, Loss : 0.6571696996688843\n",
            "Batch : 643, Loss : 0.6184627413749695\n",
            "Batch : 644, Loss : 0.7744106650352478\n",
            "Batch : 645, Loss : 0.40458109974861145\n",
            "Batch : 646, Loss : 0.4437665045261383\n",
            "Batch : 647, Loss : 0.5751045346260071\n",
            "Batch : 648, Loss : 0.5504878163337708\n",
            "Batch : 649, Loss : 0.4161003828048706\n",
            "Batch : 650, Loss : 0.4851253926753998\n",
            "Batch : 651, Loss : 0.6139124035835266\n",
            "Batch : 652, Loss : 0.4354691207408905\n",
            "Batch : 653, Loss : 0.5387147665023804\n",
            "Batch : 654, Loss : 0.6508846879005432\n",
            "Batch : 655, Loss : 0.5535870790481567\n",
            "Batch : 656, Loss : 0.45574265718460083\n",
            "Batch : 657, Loss : 0.4413255453109741\n",
            "Batch : 658, Loss : 0.48304513096809387\n",
            "Batch : 659, Loss : 0.6964683532714844\n",
            "Batch : 660, Loss : 0.49371543526649475\n",
            "Batch : 661, Loss : 0.4677797853946686\n",
            "Batch : 662, Loss : 0.4939926266670227\n",
            "Batch : 663, Loss : 0.39179810881614685\n",
            "Batch : 664, Loss : 0.7198857665061951\n",
            "Batch : 665, Loss : 0.6279638409614563\n",
            "Batch : 666, Loss : 0.5160936117172241\n",
            "Batch : 667, Loss : 0.4766063392162323\n",
            "Batch : 668, Loss : 0.46096470952033997\n",
            "Batch : 669, Loss : 0.5878145098686218\n",
            "Batch : 670, Loss : 0.6476009488105774\n",
            "Batch : 671, Loss : 0.4549466371536255\n",
            "Batch : 672, Loss : 0.5051934719085693\n",
            "Batch : 673, Loss : 0.5578594207763672\n",
            "Batch : 674, Loss : 0.5065392851829529\n",
            "Batch : 675, Loss : 0.5656805038452148\n",
            "Batch : 676, Loss : 0.5763041973114014\n",
            "Batch : 677, Loss : 0.48387226462364197\n",
            "Batch : 678, Loss : 0.6386758685112\n",
            "Batch : 679, Loss : 0.5507338047027588\n",
            "Batch : 680, Loss : 0.5353285670280457\n",
            "Batch : 681, Loss : 0.42645251750946045\n",
            "Batch : 682, Loss : 0.5422599911689758\n",
            "Batch : 683, Loss : 0.5536065101623535\n",
            "Batch : 684, Loss : 0.5504087209701538\n",
            "Batch : 685, Loss : 0.4125378429889679\n",
            "Batch : 686, Loss : 0.4137825071811676\n",
            "Batch : 687, Loss : 0.5465666651725769\n",
            "Batch : 688, Loss : 0.6470983028411865\n",
            "Batch : 689, Loss : 0.4398529827594757\n",
            "Batch : 690, Loss : 0.4097956120967865\n",
            "Batch : 691, Loss : 0.4725840389728546\n",
            "Batch : 692, Loss : 0.4881770610809326\n",
            "Batch : 693, Loss : 0.6663703918457031\n",
            "Batch : 694, Loss : 0.5448688268661499\n",
            "Batch : 695, Loss : 0.458759069442749\n",
            "Batch : 696, Loss : 0.5231155753135681\n",
            "Batch : 697, Loss : 0.48817479610443115\n",
            "Batch : 698, Loss : 0.5027228593826294\n",
            "Batch : 699, Loss : 0.42564472556114197\n",
            "Batch : 700, Loss : 0.44619616866111755\n",
            "Batch : 701, Loss : 0.4578293561935425\n",
            "Batch : 702, Loss : 0.5984746217727661\n",
            "Batch : 703, Loss : 0.5896571278572083\n",
            "Batch : 704, Loss : 0.6333336234092712\n",
            "Batch : 705, Loss : 0.6299439072608948\n",
            "Batch : 706, Loss : 0.5642422437667847\n",
            "Batch : 707, Loss : 0.4205700755119324\n",
            "Batch : 708, Loss : 0.49147117137908936\n",
            "Batch : 709, Loss : 0.3740175664424896\n",
            "Batch : 710, Loss : 0.4444361627101898\n",
            "Batch : 711, Loss : 0.47353270649909973\n",
            "Batch : 712, Loss : 0.4632008373737335\n",
            "Batch : 713, Loss : 0.40956172347068787\n",
            "Batch : 714, Loss : 0.4575785994529724\n",
            "Batch : 715, Loss : 0.5997916460037231\n",
            "Batch : 716, Loss : 0.5587028861045837\n",
            "Batch : 717, Loss : 0.6219495534896851\n",
            "Batch : 718, Loss : 0.46764057874679565\n",
            "Batch : 719, Loss : 0.42283880710601807\n",
            "Batch : 720, Loss : 0.6274329423904419\n",
            "Batch : 721, Loss : 0.6963991522789001\n",
            "Batch : 722, Loss : 0.5951130986213684\n",
            "Batch : 723, Loss : 0.7534489035606384\n",
            "Batch : 724, Loss : 0.3789973556995392\n",
            "Batch : 725, Loss : 0.41547462344169617\n",
            "Batch : 726, Loss : 0.42830216884613037\n",
            "Batch : 727, Loss : 0.5148752927780151\n",
            "Batch : 728, Loss : 0.429460346698761\n",
            "Batch : 729, Loss : 0.5083750486373901\n",
            "Batch : 730, Loss : 0.4218052625656128\n",
            "Batch : 731, Loss : 0.4733242690563202\n",
            "Batch : 732, Loss : 0.4425753355026245\n",
            "Batch : 733, Loss : 0.4330650269985199\n",
            "Batch : 734, Loss : 0.6849411129951477\n",
            "Batch : 735, Loss : 0.68958979845047\n",
            "Batch : 736, Loss : 0.49643510580062866\n",
            "Batch : 737, Loss : 0.5540010333061218\n",
            "Batch : 738, Loss : 0.4976038336753845\n",
            "Batch : 739, Loss : 0.477131187915802\n",
            "Batch : 740, Loss : 0.64129239320755\n",
            "Batch : 741, Loss : 0.4989469051361084\n",
            "Batch : 742, Loss : 0.5141832232475281\n",
            "Batch : 743, Loss : 0.47083863615989685\n",
            "Batch : 744, Loss : 0.5053316354751587\n",
            "Batch : 745, Loss : 0.6712424755096436\n",
            "Batch : 746, Loss : 0.5613251328468323\n",
            "Batch : 747, Loss : 0.5745558142662048\n",
            "Batch : 748, Loss : 0.5248199105262756\n",
            "Batch : 749, Loss : 0.613045334815979\n",
            "Batch : 750, Loss : 0.2913479506969452\n",
            "Batch : 751, Loss : 0.5632551908493042\n",
            "Batch : 752, Loss : 0.5832914710044861\n",
            "Batch : 753, Loss : 0.46341782808303833\n",
            "Batch : 754, Loss : 0.6201760768890381\n",
            "Batch : 755, Loss : 0.5420864224433899\n",
            "Batch : 756, Loss : 0.84377521276474\n",
            "Batch : 757, Loss : 0.5042423605918884\n",
            "Batch : 758, Loss : 0.6136787533760071\n",
            "Batch : 759, Loss : 0.4500555694103241\n",
            "Batch : 760, Loss : 0.6523587703704834\n",
            "Batch : 761, Loss : 0.5635911822319031\n",
            "Batch : 762, Loss : 0.47112834453582764\n",
            "Batch : 763, Loss : 0.5069670081138611\n",
            "Batch : 764, Loss : 0.38210833072662354\n",
            "Batch : 765, Loss : 0.5480536818504333\n",
            "Batch : 766, Loss : 0.5163121223449707\n",
            "Batch : 767, Loss : 0.729541540145874\n",
            "Batch : 768, Loss : 0.3420345187187195\n",
            "Batch : 769, Loss : 0.4789835214614868\n",
            "Batch : 770, Loss : 0.3277387022972107\n",
            "Batch : 771, Loss : 0.5058066248893738\n",
            "Batch : 772, Loss : 0.5882844924926758\n",
            "Batch : 773, Loss : 0.7640483975410461\n",
            "Batch : 774, Loss : 0.32350265979766846\n",
            "Batch : 775, Loss : 0.4494459331035614\n",
            "Batch : 776, Loss : 0.38119783997535706\n",
            "Batch : 777, Loss : 0.49863335490226746\n",
            "Batch : 778, Loss : 0.3559899628162384\n",
            "Batch : 779, Loss : 0.5740370154380798\n",
            "Batch : 780, Loss : 0.48958754539489746\n",
            "Batch : 781, Loss : 0.61456298828125\n",
            "Batch : 782, Loss : 0.4971905052661896\n",
            "Batch : 783, Loss : 0.4977962076663971\n",
            "Batch : 784, Loss : 0.6193970441818237\n",
            "Batch : 785, Loss : 0.45555979013442993\n",
            "Batch : 786, Loss : 0.43093425035476685\n",
            "Batch : 787, Loss : 0.4418158233165741\n",
            "Batch : 788, Loss : 0.6158883571624756\n",
            "Batch : 789, Loss : 0.6248006224632263\n",
            "Batch : 790, Loss : 0.4168377220630646\n",
            "Batch : 791, Loss : 0.5019738078117371\n",
            "Batch : 792, Loss : 0.620703935623169\n",
            "Batch : 793, Loss : 0.5305938720703125\n",
            "Batch : 794, Loss : 0.3385610580444336\n",
            "Batch : 795, Loss : 0.46807268261909485\n",
            "Batch : 796, Loss : 0.4047859013080597\n",
            "Batch : 797, Loss : 0.5522545576095581\n",
            "Batch : 798, Loss : 0.5142382979393005\n",
            "Batch : 799, Loss : 0.4059399962425232\n",
            "Batch : 800, Loss : 0.6923123598098755\n",
            "Batch : 801, Loss : 0.4306972622871399\n",
            "Batch : 802, Loss : 0.4158947765827179\n",
            "Batch : 803, Loss : 0.707839846611023\n",
            "Batch : 804, Loss : 0.4699958562850952\n",
            "Batch : 805, Loss : 0.44341179728507996\n",
            "Batch : 806, Loss : 0.38740116357803345\n",
            "Batch : 807, Loss : 0.43350139260292053\n",
            "Batch : 808, Loss : 0.3760415315628052\n",
            "Batch : 809, Loss : 0.4260888695716858\n",
            "Batch : 810, Loss : 0.4458695650100708\n",
            "Batch : 811, Loss : 0.44243699312210083\n",
            "Batch : 812, Loss : 0.46253788471221924\n",
            "Batch : 813, Loss : 0.5159772038459778\n",
            "Batch : 814, Loss : 0.5008407235145569\n",
            "Batch : 815, Loss : 0.3723308742046356\n",
            "Batch : 816, Loss : 0.7261995077133179\n",
            "Batch : 817, Loss : 0.612270176410675\n",
            "Batch : 818, Loss : 0.5787948369979858\n",
            "Batch : 819, Loss : 0.43123936653137207\n",
            "Batch : 820, Loss : 0.5507197976112366\n",
            "Batch : 821, Loss : 0.4345553517341614\n",
            "Batch : 822, Loss : 0.33030009269714355\n",
            "Batch : 823, Loss : 0.7333584427833557\n",
            "Batch : 824, Loss : 0.6298323273658752\n",
            "Batch : 825, Loss : 0.5627565383911133\n",
            "Batch : 826, Loss : 0.5669040083885193\n",
            "Batch : 827, Loss : 0.39229926466941833\n",
            "Batch : 828, Loss : 0.630530059337616\n",
            "Batch : 829, Loss : 0.42733004689216614\n",
            "Batch : 830, Loss : 0.5387323498725891\n",
            "Batch : 831, Loss : 0.6214930415153503\n",
            "Batch : 832, Loss : 0.500807523727417\n",
            "Batch : 833, Loss : 0.42095667123794556\n",
            "Batch : 834, Loss : 0.7936428785324097\n",
            "Batch : 835, Loss : 0.5531582832336426\n",
            "Batch : 836, Loss : 0.48972150683403015\n",
            "Batch : 837, Loss : 0.47612228989601135\n",
            "Batch : 838, Loss : 0.5288729667663574\n",
            "Batch : 839, Loss : 0.586780846118927\n",
            "Batch : 840, Loss : 0.4257933497428894\n",
            "Batch : 841, Loss : 0.5973652005195618\n",
            "Batch : 842, Loss : 0.6350029706954956\n",
            "Batch : 843, Loss : 0.7392994165420532\n",
            "Batch : 844, Loss : 0.4703526794910431\n",
            "Batch : 845, Loss : 0.5000895261764526\n",
            "Batch : 846, Loss : 0.539607584476471\n",
            "Batch : 847, Loss : 0.7022209763526917\n",
            "Batch : 848, Loss : 0.7136786580085754\n",
            "Batch : 849, Loss : 0.4853260815143585\n",
            "Batch : 850, Loss : 0.33139413595199585\n",
            "Batch : 851, Loss : 0.6842076182365417\n",
            "Batch : 852, Loss : 0.7573001980781555\n",
            "Batch : 853, Loss : 0.40675634145736694\n",
            "Batch : 854, Loss : 0.620120108127594\n",
            "Batch : 855, Loss : 0.6637427806854248\n",
            "Batch : 856, Loss : 0.46669939160346985\n",
            "Batch : 857, Loss : 0.49782949686050415\n",
            "Batch : 858, Loss : 0.5685492753982544\n",
            "Batch : 859, Loss : 0.4236353635787964\n",
            "Batch : 860, Loss : 0.5635806918144226\n",
            "Batch : 861, Loss : 0.5206202864646912\n",
            "Batch : 862, Loss : 0.5116319060325623\n",
            "Batch : 863, Loss : 0.4900817573070526\n",
            "Batch : 864, Loss : 0.515123724937439\n",
            "Batch : 865, Loss : 0.40717872977256775\n",
            "Batch : 866, Loss : 0.5410979390144348\n",
            "Batch : 867, Loss : 0.49500831961631775\n",
            "Batch : 868, Loss : 0.6472765207290649\n",
            "Batch : 869, Loss : 0.5461301803588867\n",
            "Batch : 870, Loss : 0.5176955461502075\n",
            "Batch : 871, Loss : 0.5655606389045715\n",
            "Batch : 872, Loss : 0.5693319439888\n",
            "Batch : 873, Loss : 0.5653111338615417\n",
            "Batch : 874, Loss : 0.37810519337654114\n",
            "Batch : 875, Loss : 0.7358488440513611\n",
            "Batch : 876, Loss : 0.5698881149291992\n",
            "Batch : 877, Loss : 0.6139470338821411\n",
            "Batch : 878, Loss : 0.34577086567878723\n",
            "Batch : 879, Loss : 0.6277323365211487\n",
            "Batch : 880, Loss : 0.5997311472892761\n",
            "Batch : 881, Loss : 0.534949004650116\n",
            "Batch : 882, Loss : 0.4935959577560425\n",
            "Batch : 883, Loss : 0.45371076464653015\n",
            "Batch : 884, Loss : 0.5538452863693237\n",
            "Batch : 885, Loss : 0.413475900888443\n",
            "Batch : 886, Loss : 0.4593076705932617\n",
            "Batch : 887, Loss : 0.43663278222084045\n",
            "Batch : 888, Loss : 0.4598645269870758\n",
            "Batch : 889, Loss : 0.576832115650177\n",
            "Batch : 890, Loss : 0.4581853449344635\n",
            "Batch : 891, Loss : 0.528995156288147\n",
            "Batch : 892, Loss : 0.42248544096946716\n",
            "Batch : 893, Loss : 0.5540679693222046\n",
            "Batch : 894, Loss : 0.5265664458274841\n",
            "Batch : 895, Loss : 0.565299391746521\n",
            "Batch : 896, Loss : 0.4312386214733124\n",
            "Batch : 897, Loss : 0.4302886426448822\n",
            "Batch : 898, Loss : 0.5852084755897522\n",
            "Batch : 899, Loss : 0.5270455479621887\n",
            "Batch : 900, Loss : 0.4053875505924225\n",
            "Batch : 901, Loss : 0.632056713104248\n",
            "Batch : 902, Loss : 0.45742520689964294\n",
            "Batch : 903, Loss : 0.40273886919021606\n",
            "Batch : 904, Loss : 0.5205219388008118\n",
            "Batch : 905, Loss : 0.7133950591087341\n",
            "Batch : 906, Loss : 0.47104090452194214\n",
            "Batch : 907, Loss : 0.39879724383354187\n",
            "Batch : 908, Loss : 0.5062455534934998\n",
            "Batch : 909, Loss : 0.5225893259048462\n",
            "Batch : 910, Loss : 0.9170131683349609\n",
            "Batch : 911, Loss : 0.49813568592071533\n",
            "Batch : 912, Loss : 0.43680208921432495\n",
            "Batch : 913, Loss : 0.3852928876876831\n",
            "Batch : 914, Loss : 0.49074071645736694\n",
            "Batch : 915, Loss : 0.6437849402427673\n",
            "Batch : 916, Loss : 0.5240801572799683\n",
            "Batch : 917, Loss : 0.5726785063743591\n",
            "Batch : 918, Loss : 0.2948688268661499\n",
            "Batch : 919, Loss : 0.6172115206718445\n",
            "Batch : 920, Loss : 0.32347914576530457\n",
            "Batch : 921, Loss : 0.5481526255607605\n",
            "Batch : 922, Loss : 0.46896660327911377\n",
            "Batch : 923, Loss : 0.5070793628692627\n",
            "Batch : 924, Loss : 0.41526690125465393\n",
            "Batch : 925, Loss : 0.5535571575164795\n",
            "Batch : 926, Loss : 0.45536676049232483\n",
            "Batch : 927, Loss : 0.611558735370636\n",
            "Batch : 928, Loss : 0.6217048168182373\n",
            "Batch : 929, Loss : 0.5234322547912598\n",
            "Batch : 930, Loss : 0.5356301069259644\n",
            "Batch : 931, Loss : 0.3758755624294281\n",
            "Batch : 932, Loss : 0.5303642153739929\n",
            "Batch : 933, Loss : 0.4297572672367096\n",
            "Batch : 934, Loss : 0.5452542304992676\n",
            "Batch : 935, Loss : 0.4517143964767456\n",
            "Batch : 936, Loss : 0.5280374884605408\n",
            "Batch : 937, Loss : 0.4065163731575012\n",
            "Batch : 938, Loss : 0.5931972861289978\n",
            "Training loss: 0.5585833238894498\n",
            "Batch : 1, Loss : 0.6356948614120483\n",
            "Batch : 2, Loss : 0.4147498905658722\n",
            "Batch : 3, Loss : 0.412541002035141\n",
            "Batch : 4, Loss : 0.5823872089385986\n",
            "Batch : 5, Loss : 0.4834054708480835\n",
            "Batch : 6, Loss : 0.6392713785171509\n",
            "Batch : 7, Loss : 0.6389760971069336\n",
            "Batch : 8, Loss : 0.6290040612220764\n",
            "Batch : 9, Loss : 0.7158528566360474\n",
            "Batch : 10, Loss : 0.4931751787662506\n",
            "Batch : 11, Loss : 0.6125839948654175\n",
            "Batch : 12, Loss : 0.4732195734977722\n",
            "Batch : 13, Loss : 0.6693628430366516\n",
            "Batch : 14, Loss : 0.6834976077079773\n",
            "Batch : 15, Loss : 0.5206367373466492\n",
            "Batch : 16, Loss : 0.6413967609405518\n",
            "Batch : 17, Loss : 0.6825434565544128\n",
            "Batch : 18, Loss : 0.590497612953186\n",
            "Batch : 19, Loss : 0.4336681663990021\n",
            "Batch : 20, Loss : 0.47732844948768616\n",
            "Batch : 21, Loss : 0.6007091403007507\n",
            "Batch : 22, Loss : 0.5597197413444519\n",
            "Batch : 23, Loss : 0.6066546440124512\n",
            "Batch : 24, Loss : 0.5348541736602783\n",
            "Batch : 25, Loss : 0.5595347881317139\n",
            "Batch : 26, Loss : 0.5063980221748352\n",
            "Batch : 27, Loss : 0.544389545917511\n",
            "Batch : 28, Loss : 0.35796719789505005\n",
            "Batch : 29, Loss : 0.37171974778175354\n",
            "Batch : 30, Loss : 0.6367772221565247\n",
            "Batch : 31, Loss : 0.5624595284461975\n",
            "Batch : 32, Loss : 0.6946349740028381\n",
            "Batch : 33, Loss : 0.593445360660553\n",
            "Batch : 34, Loss : 0.46085378527641296\n",
            "Batch : 35, Loss : 0.40207406878471375\n",
            "Batch : 36, Loss : 0.48763373494148254\n",
            "Batch : 37, Loss : 0.40017303824424744\n",
            "Batch : 38, Loss : 0.4891621470451355\n",
            "Batch : 39, Loss : 0.6023643612861633\n",
            "Batch : 40, Loss : 0.5340707898139954\n",
            "Batch : 41, Loss : 0.422834575176239\n",
            "Batch : 42, Loss : 0.5564273595809937\n",
            "Batch : 43, Loss : 0.5232897400856018\n",
            "Batch : 44, Loss : 0.634660542011261\n",
            "Batch : 45, Loss : 0.38203975558280945\n",
            "Batch : 46, Loss : 0.6382688283920288\n",
            "Batch : 47, Loss : 0.5039346218109131\n",
            "Batch : 48, Loss : 0.560897946357727\n",
            "Batch : 49, Loss : 0.46687912940979004\n",
            "Batch : 50, Loss : 0.5752023458480835\n",
            "Batch : 51, Loss : 0.6039116978645325\n",
            "Batch : 52, Loss : 0.5433072447776794\n",
            "Batch : 53, Loss : 0.4111011028289795\n",
            "Batch : 54, Loss : 0.45577648282051086\n",
            "Batch : 55, Loss : 0.7245839238166809\n",
            "Batch : 56, Loss : 0.5250380039215088\n",
            "Batch : 57, Loss : 0.3363724648952484\n",
            "Batch : 58, Loss : 0.583378791809082\n",
            "Batch : 59, Loss : 0.7524401545524597\n",
            "Batch : 60, Loss : 0.473690390586853\n",
            "Batch : 61, Loss : 0.608584463596344\n",
            "Batch : 62, Loss : 0.3840753734111786\n",
            "Batch : 63, Loss : 0.6069366335868835\n",
            "Batch : 64, Loss : 0.5138051509857178\n",
            "Batch : 65, Loss : 0.34529513120651245\n",
            "Batch : 66, Loss : 0.6921733021736145\n",
            "Batch : 67, Loss : 0.6300727725028992\n",
            "Batch : 68, Loss : 0.5872809886932373\n",
            "Batch : 69, Loss : 0.4977303147315979\n",
            "Batch : 70, Loss : 0.6416444182395935\n",
            "Batch : 71, Loss : 0.5221254825592041\n",
            "Batch : 72, Loss : 0.5538134574890137\n",
            "Batch : 73, Loss : 0.39960822463035583\n",
            "Batch : 74, Loss : 0.6097770929336548\n",
            "Batch : 75, Loss : 0.38110148906707764\n",
            "Batch : 76, Loss : 0.31170621514320374\n",
            "Batch : 77, Loss : 0.4704631567001343\n",
            "Batch : 78, Loss : 0.5606041550636292\n",
            "Batch : 79, Loss : 0.7680681943893433\n",
            "Batch : 80, Loss : 0.4534377455711365\n",
            "Batch : 81, Loss : 0.47612807154655457\n",
            "Batch : 82, Loss : 0.5013222098350525\n",
            "Batch : 83, Loss : 0.3738086223602295\n",
            "Batch : 84, Loss : 0.45783868432044983\n",
            "Batch : 85, Loss : 0.616877555847168\n",
            "Batch : 86, Loss : 0.6739408373832703\n",
            "Batch : 87, Loss : 0.4576965570449829\n",
            "Batch : 88, Loss : 0.6546363830566406\n",
            "Batch : 89, Loss : 0.4681471884250641\n",
            "Batch : 90, Loss : 0.692345142364502\n",
            "Batch : 91, Loss : 0.47542423009872437\n",
            "Batch : 92, Loss : 0.5568477511405945\n",
            "Batch : 93, Loss : 0.49905359745025635\n",
            "Batch : 94, Loss : 0.5497806668281555\n",
            "Batch : 95, Loss : 0.372529000043869\n",
            "Batch : 96, Loss : 0.9063986539840698\n",
            "Batch : 97, Loss : 0.6811534762382507\n",
            "Batch : 98, Loss : 0.6376705169677734\n",
            "Batch : 99, Loss : 0.47358161211013794\n",
            "Batch : 100, Loss : 0.5468723177909851\n",
            "Batch : 101, Loss : 0.31131452322006226\n",
            "Batch : 102, Loss : 0.3693983554840088\n",
            "Batch : 103, Loss : 0.4831930994987488\n",
            "Batch : 104, Loss : 0.38822242617607117\n",
            "Batch : 105, Loss : 0.3223194479942322\n",
            "Batch : 106, Loss : 0.5958085060119629\n",
            "Batch : 107, Loss : 0.3582664430141449\n",
            "Batch : 108, Loss : 0.33435380458831787\n",
            "Batch : 109, Loss : 0.48369136452674866\n",
            "Batch : 110, Loss : 0.414385586977005\n",
            "Batch : 111, Loss : 0.5013136863708496\n",
            "Batch : 112, Loss : 0.44198280572891235\n",
            "Batch : 113, Loss : 0.383647084236145\n",
            "Batch : 114, Loss : 0.542077898979187\n",
            "Batch : 115, Loss : 0.48286551237106323\n",
            "Batch : 116, Loss : 0.4216572344303131\n",
            "Batch : 117, Loss : 0.5898574590682983\n",
            "Batch : 118, Loss : 0.4069972634315491\n",
            "Batch : 119, Loss : 0.5021404027938843\n",
            "Batch : 120, Loss : 0.2954724133014679\n",
            "Batch : 121, Loss : 0.49866920709609985\n",
            "Batch : 122, Loss : 0.5413290858268738\n",
            "Batch : 123, Loss : 0.5737959146499634\n",
            "Batch : 124, Loss : 0.42475974559783936\n",
            "Batch : 125, Loss : 0.47579270601272583\n",
            "Batch : 126, Loss : 0.48788055777549744\n",
            "Batch : 127, Loss : 0.37976667284965515\n",
            "Batch : 128, Loss : 0.4357292354106903\n",
            "Batch : 129, Loss : 0.480413019657135\n",
            "Batch : 130, Loss : 0.5439569354057312\n",
            "Batch : 131, Loss : 0.38240987062454224\n",
            "Batch : 132, Loss : 0.4656597673892975\n",
            "Batch : 133, Loss : 0.5800595879554749\n",
            "Batch : 134, Loss : 0.6847324371337891\n",
            "Batch : 135, Loss : 0.4946117401123047\n",
            "Batch : 136, Loss : 0.38465747237205505\n",
            "Batch : 137, Loss : 0.47439223527908325\n",
            "Batch : 138, Loss : 0.604051947593689\n",
            "Batch : 139, Loss : 0.5481598377227783\n",
            "Batch : 140, Loss : 0.44193896651268005\n",
            "Batch : 141, Loss : 0.38623204827308655\n",
            "Batch : 142, Loss : 0.4354802966117859\n",
            "Batch : 143, Loss : 0.41079315543174744\n",
            "Batch : 144, Loss : 0.5799474120140076\n",
            "Batch : 145, Loss : 0.5516852140426636\n",
            "Batch : 146, Loss : 0.4143475592136383\n",
            "Batch : 147, Loss : 0.410806268453598\n",
            "Batch : 148, Loss : 0.5859801769256592\n",
            "Batch : 149, Loss : 0.4468074440956116\n",
            "Batch : 150, Loss : 0.589004635810852\n",
            "Batch : 151, Loss : 0.39173629879951477\n",
            "Batch : 152, Loss : 0.6059995293617249\n",
            "Batch : 153, Loss : 0.5213691592216492\n",
            "Batch : 154, Loss : 0.575724720954895\n",
            "Batch : 155, Loss : 0.34623557329177856\n",
            "Batch : 156, Loss : 0.5093526840209961\n",
            "Batch : 157, Loss : 0.47168201208114624\n",
            "Batch : 158, Loss : 0.5001661777496338\n",
            "Batch : 159, Loss : 0.4914146661758423\n",
            "Batch : 160, Loss : 0.5181471705436707\n",
            "Batch : 161, Loss : 0.4684002101421356\n",
            "Batch : 162, Loss : 0.46048209071159363\n",
            "Batch : 163, Loss : 0.48989662528038025\n",
            "Batch : 164, Loss : 0.42107927799224854\n",
            "Batch : 165, Loss : 0.5982921719551086\n",
            "Batch : 166, Loss : 0.4295231103897095\n",
            "Batch : 167, Loss : 0.3239489495754242\n",
            "Batch : 168, Loss : 0.5571085810661316\n",
            "Batch : 169, Loss : 0.6668899655342102\n",
            "Batch : 170, Loss : 0.5271215438842773\n",
            "Batch : 171, Loss : 0.46221041679382324\n",
            "Batch : 172, Loss : 0.44696176052093506\n",
            "Batch : 173, Loss : 0.7911372184753418\n",
            "Batch : 174, Loss : 0.5813747644424438\n",
            "Batch : 175, Loss : 0.25776079297065735\n",
            "Batch : 176, Loss : 0.5892091393470764\n",
            "Batch : 177, Loss : 0.6360450983047485\n",
            "Batch : 178, Loss : 0.6885422468185425\n",
            "Batch : 179, Loss : 0.46546173095703125\n",
            "Batch : 180, Loss : 0.40806540846824646\n",
            "Batch : 181, Loss : 0.5446665287017822\n",
            "Batch : 182, Loss : 0.45931562781333923\n",
            "Batch : 183, Loss : 0.8064095377922058\n",
            "Batch : 184, Loss : 0.42140984535217285\n",
            "Batch : 185, Loss : 0.349343478679657\n",
            "Batch : 186, Loss : 0.48348429799079895\n",
            "Batch : 187, Loss : 0.4307001233100891\n",
            "Batch : 188, Loss : 0.44092705845832825\n",
            "Batch : 189, Loss : 0.4729515612125397\n",
            "Batch : 190, Loss : 0.5155702829360962\n",
            "Batch : 191, Loss : 0.5238186120986938\n",
            "Batch : 192, Loss : 0.5283805131912231\n",
            "Batch : 193, Loss : 0.4517722725868225\n",
            "Batch : 194, Loss : 0.6642010807991028\n",
            "Batch : 195, Loss : 0.4545316696166992\n",
            "Batch : 196, Loss : 0.4812290668487549\n",
            "Batch : 197, Loss : 0.47652316093444824\n",
            "Batch : 198, Loss : 0.3543289005756378\n",
            "Batch : 199, Loss : 0.613113522529602\n",
            "Batch : 200, Loss : 0.392569363117218\n",
            "Batch : 201, Loss : 0.4556262493133545\n",
            "Batch : 202, Loss : 0.46785226464271545\n",
            "Batch : 203, Loss : 0.5554577112197876\n",
            "Batch : 204, Loss : 0.5986865162849426\n",
            "Batch : 205, Loss : 0.40654876828193665\n",
            "Batch : 206, Loss : 0.4599597454071045\n",
            "Batch : 207, Loss : 0.5668140053749084\n",
            "Batch : 208, Loss : 0.699049711227417\n",
            "Batch : 209, Loss : 0.34945148229599\n",
            "Batch : 210, Loss : 0.5617238283157349\n",
            "Batch : 211, Loss : 0.3961317241191864\n",
            "Batch : 212, Loss : 0.40609219670295715\n",
            "Batch : 213, Loss : 0.3693051040172577\n",
            "Batch : 214, Loss : 0.6214379668235779\n",
            "Batch : 215, Loss : 0.37041980028152466\n",
            "Batch : 216, Loss : 0.38487082719802856\n",
            "Batch : 217, Loss : 0.43825915455818176\n",
            "Batch : 218, Loss : 0.3756197392940521\n",
            "Batch : 219, Loss : 0.39350080490112305\n",
            "Batch : 220, Loss : 0.5701249241828918\n",
            "Batch : 221, Loss : 0.5872794985771179\n",
            "Batch : 222, Loss : 0.5625808238983154\n",
            "Batch : 223, Loss : 0.6102019548416138\n",
            "Batch : 224, Loss : 0.4462260901927948\n",
            "Batch : 225, Loss : 0.31554850935935974\n",
            "Batch : 226, Loss : 0.5762463808059692\n",
            "Batch : 227, Loss : 0.6790136694908142\n",
            "Batch : 228, Loss : 0.5000221133232117\n",
            "Batch : 229, Loss : 0.49133315682411194\n",
            "Batch : 230, Loss : 0.5718491077423096\n",
            "Batch : 231, Loss : 0.488829106092453\n",
            "Batch : 232, Loss : 0.4560350477695465\n",
            "Batch : 233, Loss : 0.5417503118515015\n",
            "Batch : 234, Loss : 0.46814367175102234\n",
            "Batch : 235, Loss : 0.2950098216533661\n",
            "Batch : 236, Loss : 0.38910961151123047\n",
            "Batch : 237, Loss : 0.5257121324539185\n",
            "Batch : 238, Loss : 0.3772169351577759\n",
            "Batch : 239, Loss : 0.4805540442466736\n",
            "Batch : 240, Loss : 0.5680210590362549\n",
            "Batch : 241, Loss : 0.38553497195243835\n",
            "Batch : 242, Loss : 0.493986576795578\n",
            "Batch : 243, Loss : 0.6642968654632568\n",
            "Batch : 244, Loss : 0.4818149507045746\n",
            "Batch : 245, Loss : 0.43781670928001404\n",
            "Batch : 246, Loss : 0.4784111976623535\n",
            "Batch : 247, Loss : 0.42416900396347046\n",
            "Batch : 248, Loss : 0.5105816721916199\n",
            "Batch : 249, Loss : 0.4472183883190155\n",
            "Batch : 250, Loss : 0.5656689405441284\n",
            "Batch : 251, Loss : 0.5608875751495361\n",
            "Batch : 252, Loss : 0.4474943280220032\n",
            "Batch : 253, Loss : 0.5617737770080566\n",
            "Batch : 254, Loss : 0.32318899035453796\n",
            "Batch : 255, Loss : 0.5250353813171387\n",
            "Batch : 256, Loss : 0.4655267298221588\n",
            "Batch : 257, Loss : 0.3078234791755676\n",
            "Batch : 258, Loss : 0.5063470602035522\n",
            "Batch : 259, Loss : 0.49766775965690613\n",
            "Batch : 260, Loss : 0.34648823738098145\n",
            "Batch : 261, Loss : 0.48711174726486206\n",
            "Batch : 262, Loss : 0.4787284731864929\n",
            "Batch : 263, Loss : 0.37079405784606934\n",
            "Batch : 264, Loss : 0.5273830890655518\n",
            "Batch : 265, Loss : 0.4263918101787567\n",
            "Batch : 266, Loss : 0.5197557210922241\n",
            "Batch : 267, Loss : 0.5629727244377136\n",
            "Batch : 268, Loss : 0.6238498091697693\n",
            "Batch : 269, Loss : 0.46440327167510986\n",
            "Batch : 270, Loss : 0.48671630024909973\n",
            "Batch : 271, Loss : 0.5307832360267639\n",
            "Batch : 272, Loss : 0.3705074191093445\n",
            "Batch : 273, Loss : 0.6657166481018066\n",
            "Batch : 274, Loss : 0.5488661527633667\n",
            "Batch : 275, Loss : 0.37814193964004517\n",
            "Batch : 276, Loss : 0.6889970898628235\n",
            "Batch : 277, Loss : 0.4697342813014984\n",
            "Batch : 278, Loss : 0.5035834312438965\n",
            "Batch : 279, Loss : 0.4144604504108429\n",
            "Batch : 280, Loss : 0.4310908615589142\n",
            "Batch : 281, Loss : 0.479308545589447\n",
            "Batch : 282, Loss : 0.42159539461135864\n",
            "Batch : 283, Loss : 0.4672624468803406\n",
            "Batch : 284, Loss : 0.6027910113334656\n",
            "Batch : 285, Loss : 0.35558637976646423\n",
            "Batch : 286, Loss : 0.47763803601264954\n",
            "Batch : 287, Loss : 0.4769759774208069\n",
            "Batch : 288, Loss : 0.5460401773452759\n",
            "Batch : 289, Loss : 0.5259842872619629\n",
            "Batch : 290, Loss : 0.46601802110671997\n",
            "Batch : 291, Loss : 0.4922068417072296\n",
            "Batch : 292, Loss : 0.5096144676208496\n",
            "Batch : 293, Loss : 0.48217105865478516\n",
            "Batch : 294, Loss : 0.7097662091255188\n",
            "Batch : 295, Loss : 0.4820325970649719\n",
            "Batch : 296, Loss : 0.49109259247779846\n",
            "Batch : 297, Loss : 0.601264476776123\n",
            "Batch : 298, Loss : 0.578523576259613\n",
            "Batch : 299, Loss : 0.4565688371658325\n",
            "Batch : 300, Loss : 0.3577893078327179\n",
            "Batch : 301, Loss : 0.43249189853668213\n",
            "Batch : 302, Loss : 0.33633214235305786\n",
            "Batch : 303, Loss : 0.5322245955467224\n",
            "Batch : 304, Loss : 0.6862744688987732\n",
            "Batch : 305, Loss : 0.603573739528656\n",
            "Batch : 306, Loss : 0.4768597483634949\n",
            "Batch : 307, Loss : 0.4757517874240875\n",
            "Batch : 308, Loss : 0.3649251163005829\n",
            "Batch : 309, Loss : 0.5049855709075928\n",
            "Batch : 310, Loss : 0.4236452281475067\n",
            "Batch : 311, Loss : 0.5562071800231934\n",
            "Batch : 312, Loss : 0.5947803854942322\n",
            "Batch : 313, Loss : 0.5866104364395142\n",
            "Batch : 314, Loss : 0.4033202528953552\n",
            "Batch : 315, Loss : 0.49496376514434814\n",
            "Batch : 316, Loss : 0.7378882765769958\n",
            "Batch : 317, Loss : 0.4823038876056671\n",
            "Batch : 318, Loss : 0.34551286697387695\n",
            "Batch : 319, Loss : 0.5365136861801147\n",
            "Batch : 320, Loss : 0.48264601826667786\n",
            "Batch : 321, Loss : 0.45497041940689087\n",
            "Batch : 322, Loss : 0.4834262728691101\n",
            "Batch : 323, Loss : 0.6121780276298523\n",
            "Batch : 324, Loss : 0.4934794008731842\n",
            "Batch : 325, Loss : 0.45837661623954773\n",
            "Batch : 326, Loss : 0.39152792096138\n",
            "Batch : 327, Loss : 0.6685181856155396\n",
            "Batch : 328, Loss : 0.5789154171943665\n",
            "Batch : 329, Loss : 0.6886733174324036\n",
            "Batch : 330, Loss : 0.4793398976325989\n",
            "Batch : 331, Loss : 0.36569544672966003\n",
            "Batch : 332, Loss : 0.5255095958709717\n",
            "Batch : 333, Loss : 0.5322884321212769\n",
            "Batch : 334, Loss : 0.5372692942619324\n",
            "Batch : 335, Loss : 0.4801415205001831\n",
            "Batch : 336, Loss : 0.6298725605010986\n",
            "Batch : 337, Loss : 0.3661378026008606\n",
            "Batch : 338, Loss : 0.5540722608566284\n",
            "Batch : 339, Loss : 0.6755723357200623\n",
            "Batch : 340, Loss : 0.37505999207496643\n",
            "Batch : 341, Loss : 0.42690715193748474\n",
            "Batch : 342, Loss : 0.6762238144874573\n",
            "Batch : 343, Loss : 0.37795618176460266\n",
            "Batch : 344, Loss : 0.7073513865470886\n",
            "Batch : 345, Loss : 0.45653295516967773\n",
            "Batch : 346, Loss : 0.34899869561195374\n",
            "Batch : 347, Loss : 0.47846466302871704\n",
            "Batch : 348, Loss : 0.4189669191837311\n",
            "Batch : 349, Loss : 0.5155532360076904\n",
            "Batch : 350, Loss : 0.4792529046535492\n",
            "Batch : 351, Loss : 0.4053557217121124\n",
            "Batch : 352, Loss : 0.41822171211242676\n",
            "Batch : 353, Loss : 0.3732917010784149\n",
            "Batch : 354, Loss : 0.38255244493484497\n",
            "Batch : 355, Loss : 0.280691534280777\n",
            "Batch : 356, Loss : 0.5433024168014526\n",
            "Batch : 357, Loss : 0.3655836880207062\n",
            "Batch : 358, Loss : 0.6229849457740784\n",
            "Batch : 359, Loss : 0.4796120226383209\n",
            "Batch : 360, Loss : 0.4566033184528351\n",
            "Batch : 361, Loss : 0.3066292405128479\n",
            "Batch : 362, Loss : 0.41720470786094666\n",
            "Batch : 363, Loss : 0.5844429135322571\n",
            "Batch : 364, Loss : 0.5213625431060791\n",
            "Batch : 365, Loss : 0.5016241073608398\n",
            "Batch : 366, Loss : 0.6253290176391602\n",
            "Batch : 367, Loss : 0.609305739402771\n",
            "Batch : 368, Loss : 0.5480411052703857\n",
            "Batch : 369, Loss : 0.4708985686302185\n",
            "Batch : 370, Loss : 0.5447558760643005\n",
            "Batch : 371, Loss : 0.6662337779998779\n",
            "Batch : 372, Loss : 0.6909997463226318\n",
            "Batch : 373, Loss : 0.536359429359436\n",
            "Batch : 374, Loss : 0.428586483001709\n",
            "Batch : 375, Loss : 0.42628544569015503\n",
            "Batch : 376, Loss : 0.5004213452339172\n",
            "Batch : 377, Loss : 0.38793063163757324\n",
            "Batch : 378, Loss : 0.5939816236495972\n",
            "Batch : 379, Loss : 0.40691497921943665\n",
            "Batch : 380, Loss : 0.4558863341808319\n",
            "Batch : 381, Loss : 0.4157777428627014\n",
            "Batch : 382, Loss : 0.6134383082389832\n",
            "Batch : 383, Loss : 0.418388307094574\n",
            "Batch : 384, Loss : 0.5148075819015503\n",
            "Batch : 385, Loss : 0.4807819128036499\n",
            "Batch : 386, Loss : 0.5091248750686646\n",
            "Batch : 387, Loss : 0.5177081823348999\n",
            "Batch : 388, Loss : 0.47213611006736755\n",
            "Batch : 389, Loss : 0.31669700145721436\n",
            "Batch : 390, Loss : 0.45259684324264526\n",
            "Batch : 391, Loss : 0.348510205745697\n",
            "Batch : 392, Loss : 0.42395469546318054\n",
            "Batch : 393, Loss : 0.45903632044792175\n",
            "Batch : 394, Loss : 0.4197807013988495\n",
            "Batch : 395, Loss : 0.4333353340625763\n",
            "Batch : 396, Loss : 0.2531949579715729\n",
            "Batch : 397, Loss : 0.4254779517650604\n",
            "Batch : 398, Loss : 0.5315635204315186\n",
            "Batch : 399, Loss : 0.5078436732292175\n",
            "Batch : 400, Loss : 0.45756426453590393\n",
            "Batch : 401, Loss : 0.4700799286365509\n",
            "Batch : 402, Loss : 0.3248971104621887\n",
            "Batch : 403, Loss : 0.5258931517601013\n",
            "Batch : 404, Loss : 0.47250133752822876\n",
            "Batch : 405, Loss : 0.6105010509490967\n",
            "Batch : 406, Loss : 0.50052410364151\n",
            "Batch : 407, Loss : 0.5358026623725891\n",
            "Batch : 408, Loss : 0.2529197037220001\n",
            "Batch : 409, Loss : 0.5809714198112488\n",
            "Batch : 410, Loss : 0.4784952998161316\n",
            "Batch : 411, Loss : 0.445325642824173\n",
            "Batch : 412, Loss : 0.5547006726264954\n",
            "Batch : 413, Loss : 0.31662026047706604\n",
            "Batch : 414, Loss : 0.5560786128044128\n",
            "Batch : 415, Loss : 0.3672272562980652\n",
            "Batch : 416, Loss : 0.7466301321983337\n",
            "Batch : 417, Loss : 0.4398413300514221\n",
            "Batch : 418, Loss : 0.44726142287254333\n",
            "Batch : 419, Loss : 0.40548574924468994\n",
            "Batch : 420, Loss : 0.43378743529319763\n",
            "Batch : 421, Loss : 0.4741481840610504\n",
            "Batch : 422, Loss : 0.5030339360237122\n",
            "Batch : 423, Loss : 0.5560324788093567\n",
            "Batch : 424, Loss : 0.38255783915519714\n",
            "Batch : 425, Loss : 0.3794408142566681\n",
            "Batch : 426, Loss : 0.37347471714019775\n",
            "Batch : 427, Loss : 0.4369930326938629\n",
            "Batch : 428, Loss : 0.34527313709259033\n",
            "Batch : 429, Loss : 0.6140135526657104\n",
            "Batch : 430, Loss : 0.6563491225242615\n",
            "Batch : 431, Loss : 0.41758987307548523\n",
            "Batch : 432, Loss : 0.5019237995147705\n",
            "Batch : 433, Loss : 0.42024415731430054\n",
            "Batch : 434, Loss : 0.35818055272102356\n",
            "Batch : 435, Loss : 0.3321669101715088\n",
            "Batch : 436, Loss : 0.5232476592063904\n",
            "Batch : 437, Loss : 0.6400057673454285\n",
            "Batch : 438, Loss : 0.3879319429397583\n",
            "Batch : 439, Loss : 0.36707407236099243\n",
            "Batch : 440, Loss : 0.3625023066997528\n",
            "Batch : 441, Loss : 0.4874981939792633\n",
            "Batch : 442, Loss : 0.48725661635398865\n",
            "Batch : 443, Loss : 0.6242392659187317\n",
            "Batch : 444, Loss : 0.6077666878700256\n",
            "Batch : 445, Loss : 0.3899414837360382\n",
            "Batch : 446, Loss : 0.3213837146759033\n",
            "Batch : 447, Loss : 0.4894140958786011\n",
            "Batch : 448, Loss : 0.3799576163291931\n",
            "Batch : 449, Loss : 0.5809858441352844\n",
            "Batch : 450, Loss : 0.5607300996780396\n",
            "Batch : 451, Loss : 0.5002731680870056\n",
            "Batch : 452, Loss : 0.588687002658844\n",
            "Batch : 453, Loss : 0.6328263282775879\n",
            "Batch : 454, Loss : 0.7129900455474854\n",
            "Batch : 455, Loss : 0.42193952202796936\n",
            "Batch : 456, Loss : 0.5721722841262817\n",
            "Batch : 457, Loss : 0.3667786419391632\n",
            "Batch : 458, Loss : 0.5191959738731384\n",
            "Batch : 459, Loss : 0.31340622901916504\n",
            "Batch : 460, Loss : 0.4901873469352722\n",
            "Batch : 461, Loss : 0.6140351295471191\n",
            "Batch : 462, Loss : 0.39534658193588257\n",
            "Batch : 463, Loss : 0.575860857963562\n",
            "Batch : 464, Loss : 0.34017860889434814\n",
            "Batch : 465, Loss : 0.4757189452648163\n",
            "Batch : 466, Loss : 0.48831114172935486\n",
            "Batch : 467, Loss : 0.3958173990249634\n",
            "Batch : 468, Loss : 0.3230414092540741\n",
            "Batch : 469, Loss : 0.46971428394317627\n",
            "Batch : 470, Loss : 0.4303629398345947\n",
            "Batch : 471, Loss : 0.4474361538887024\n",
            "Batch : 472, Loss : 0.487804651260376\n",
            "Batch : 473, Loss : 0.7092016935348511\n",
            "Batch : 474, Loss : 0.4674193263053894\n",
            "Batch : 475, Loss : 0.5559256076812744\n",
            "Batch : 476, Loss : 0.43828171491622925\n",
            "Batch : 477, Loss : 0.4437025785446167\n",
            "Batch : 478, Loss : 0.6241051554679871\n",
            "Batch : 479, Loss : 0.4952264130115509\n",
            "Batch : 480, Loss : 0.4986633360385895\n",
            "Batch : 481, Loss : 0.4524693787097931\n",
            "Batch : 482, Loss : 0.4985540509223938\n",
            "Batch : 483, Loss : 0.5836414694786072\n",
            "Batch : 484, Loss : 0.3816050887107849\n",
            "Batch : 485, Loss : 0.5386849045753479\n",
            "Batch : 486, Loss : 0.5589578747749329\n",
            "Batch : 487, Loss : 0.5275357961654663\n",
            "Batch : 488, Loss : 0.5956553816795349\n",
            "Batch : 489, Loss : 0.5549550652503967\n",
            "Batch : 490, Loss : 0.39791783690452576\n",
            "Batch : 491, Loss : 0.4974497854709625\n",
            "Batch : 492, Loss : 0.582027018070221\n",
            "Batch : 493, Loss : 0.42996811866760254\n",
            "Batch : 494, Loss : 0.716323971748352\n",
            "Batch : 495, Loss : 0.3827623724937439\n",
            "Batch : 496, Loss : 0.6469921469688416\n",
            "Batch : 497, Loss : 0.5970796346664429\n",
            "Batch : 498, Loss : 0.6164152026176453\n",
            "Batch : 499, Loss : 0.41375505924224854\n",
            "Batch : 500, Loss : 0.46736907958984375\n",
            "Batch : 501, Loss : 0.3654214143753052\n",
            "Batch : 502, Loss : 0.5896046161651611\n",
            "Batch : 503, Loss : 0.5413380265235901\n",
            "Batch : 504, Loss : 0.5877209901809692\n",
            "Batch : 505, Loss : 0.48115846514701843\n",
            "Batch : 506, Loss : 0.25496551394462585\n",
            "Batch : 507, Loss : 0.3121189475059509\n",
            "Batch : 508, Loss : 0.47959011793136597\n",
            "Batch : 509, Loss : 0.47258061170578003\n",
            "Batch : 510, Loss : 0.42384588718414307\n",
            "Batch : 511, Loss : 0.3803083598613739\n",
            "Batch : 512, Loss : 0.4743509590625763\n",
            "Batch : 513, Loss : 0.5037421584129333\n",
            "Batch : 514, Loss : 0.7530470490455627\n",
            "Batch : 515, Loss : 0.4215640723705292\n",
            "Batch : 516, Loss : 0.4796868562698364\n",
            "Batch : 517, Loss : 0.36085081100463867\n",
            "Batch : 518, Loss : 0.5067541599273682\n",
            "Batch : 519, Loss : 0.5589330196380615\n",
            "Batch : 520, Loss : 0.33563461899757385\n",
            "Batch : 521, Loss : 0.5049785375595093\n",
            "Batch : 522, Loss : 0.6611954569816589\n",
            "Batch : 523, Loss : 0.538659393787384\n",
            "Batch : 524, Loss : 0.3724353015422821\n",
            "Batch : 525, Loss : 0.6125036478042603\n",
            "Batch : 526, Loss : 0.40102750062942505\n",
            "Batch : 527, Loss : 0.6702851057052612\n",
            "Batch : 528, Loss : 0.6133637428283691\n",
            "Batch : 529, Loss : 0.6546450257301331\n",
            "Batch : 530, Loss : 0.5507774949073792\n",
            "Batch : 531, Loss : 0.6728352904319763\n",
            "Batch : 532, Loss : 0.5684489607810974\n",
            "Batch : 533, Loss : 0.4006200134754181\n",
            "Batch : 534, Loss : 0.4649825096130371\n",
            "Batch : 535, Loss : 0.4862194359302521\n",
            "Batch : 536, Loss : 0.6848196387290955\n",
            "Batch : 537, Loss : 0.5256209969520569\n",
            "Batch : 538, Loss : 0.42421165108680725\n",
            "Batch : 539, Loss : 0.5059338808059692\n",
            "Batch : 540, Loss : 0.38739141821861267\n",
            "Batch : 541, Loss : 0.4235062599182129\n",
            "Batch : 542, Loss : 0.39261794090270996\n",
            "Batch : 543, Loss : 0.6477723121643066\n",
            "Batch : 544, Loss : 0.4978260397911072\n",
            "Batch : 545, Loss : 0.42519140243530273\n",
            "Batch : 546, Loss : 0.4725796580314636\n",
            "Batch : 547, Loss : 0.5141386985778809\n",
            "Batch : 548, Loss : 0.5660122632980347\n",
            "Batch : 549, Loss : 0.40130993723869324\n",
            "Batch : 550, Loss : 0.5073761940002441\n",
            "Batch : 551, Loss : 0.4767252802848816\n",
            "Batch : 552, Loss : 0.4849050045013428\n",
            "Batch : 553, Loss : 0.48270681500434875\n",
            "Batch : 554, Loss : 0.5962573289871216\n",
            "Batch : 555, Loss : 0.5746493339538574\n",
            "Batch : 556, Loss : 0.42949187755584717\n",
            "Batch : 557, Loss : 0.7060368061065674\n",
            "Batch : 558, Loss : 0.5798430442810059\n",
            "Batch : 559, Loss : 0.34078240394592285\n",
            "Batch : 560, Loss : 0.5087264776229858\n",
            "Batch : 561, Loss : 0.4884214401245117\n",
            "Batch : 562, Loss : 0.4125804305076599\n",
            "Batch : 563, Loss : 0.4589332640171051\n",
            "Batch : 564, Loss : 0.4138849675655365\n",
            "Batch : 565, Loss : 0.3690805733203888\n",
            "Batch : 566, Loss : 0.37425220012664795\n",
            "Batch : 567, Loss : 0.3319190442562103\n",
            "Batch : 568, Loss : 0.5803496241569519\n",
            "Batch : 569, Loss : 0.39006495475769043\n",
            "Batch : 570, Loss : 0.4337117075920105\n",
            "Batch : 571, Loss : 0.4048641622066498\n",
            "Batch : 572, Loss : 0.7863640189170837\n",
            "Batch : 573, Loss : 0.35600805282592773\n",
            "Batch : 574, Loss : 0.4621922969818115\n",
            "Batch : 575, Loss : 0.41398102045059204\n",
            "Batch : 576, Loss : 0.6817218065261841\n",
            "Batch : 577, Loss : 0.5045827031135559\n",
            "Batch : 578, Loss : 0.6292384266853333\n",
            "Batch : 579, Loss : 0.6078280210494995\n",
            "Batch : 580, Loss : 0.5314225554466248\n",
            "Batch : 581, Loss : 0.31073877215385437\n",
            "Batch : 582, Loss : 0.40339139103889465\n",
            "Batch : 583, Loss : 0.6533061265945435\n",
            "Batch : 584, Loss : 0.4305471181869507\n",
            "Batch : 585, Loss : 0.5696775913238525\n",
            "Batch : 586, Loss : 0.5344095826148987\n",
            "Batch : 587, Loss : 0.44177496433258057\n",
            "Batch : 588, Loss : 0.6261993050575256\n",
            "Batch : 589, Loss : 0.4911101460456848\n",
            "Batch : 590, Loss : 0.4557417631149292\n",
            "Batch : 591, Loss : 0.4809393584728241\n",
            "Batch : 592, Loss : 0.5725399851799011\n",
            "Batch : 593, Loss : 0.450344055891037\n",
            "Batch : 594, Loss : 0.6163626313209534\n",
            "Batch : 595, Loss : 0.4454967677593231\n",
            "Batch : 596, Loss : 0.48734086751937866\n",
            "Batch : 597, Loss : 0.6460904479026794\n",
            "Batch : 598, Loss : 0.45214584469795227\n",
            "Batch : 599, Loss : 0.3579411208629608\n",
            "Batch : 600, Loss : 0.4008316993713379\n",
            "Batch : 601, Loss : 0.5954424738883972\n",
            "Batch : 602, Loss : 0.28246045112609863\n",
            "Batch : 603, Loss : 0.4013918936252594\n",
            "Batch : 604, Loss : 0.5010966658592224\n",
            "Batch : 605, Loss : 0.6713786721229553\n",
            "Batch : 606, Loss : 0.46789512038230896\n",
            "Batch : 607, Loss : 0.4311986267566681\n",
            "Batch : 608, Loss : 0.4326111972332001\n",
            "Batch : 609, Loss : 0.44375908374786377\n",
            "Batch : 610, Loss : 0.43849533796310425\n",
            "Batch : 611, Loss : 0.47747617959976196\n",
            "Batch : 612, Loss : 0.3152519762516022\n",
            "Batch : 613, Loss : 0.4358638823032379\n",
            "Batch : 614, Loss : 0.47038209438323975\n",
            "Batch : 615, Loss : 0.37058186531066895\n",
            "Batch : 616, Loss : 0.4882315993309021\n",
            "Batch : 617, Loss : 0.6305932998657227\n",
            "Batch : 618, Loss : 0.45350292325019836\n",
            "Batch : 619, Loss : 0.4429730772972107\n",
            "Batch : 620, Loss : 0.4142506718635559\n",
            "Batch : 621, Loss : 0.6024689674377441\n",
            "Batch : 622, Loss : 0.39643481373786926\n",
            "Batch : 623, Loss : 0.5588668584823608\n",
            "Batch : 624, Loss : 0.36577194929122925\n",
            "Batch : 625, Loss : 0.4626782536506653\n",
            "Batch : 626, Loss : 0.6395241022109985\n",
            "Batch : 627, Loss : 0.5156341195106506\n",
            "Batch : 628, Loss : 0.41961896419525146\n",
            "Batch : 629, Loss : 0.37711894512176514\n",
            "Batch : 630, Loss : 0.4904869794845581\n",
            "Batch : 631, Loss : 0.4547743499279022\n",
            "Batch : 632, Loss : 0.5593658685684204\n",
            "Batch : 633, Loss : 0.35683512687683105\n",
            "Batch : 634, Loss : 0.4611586034297943\n",
            "Batch : 635, Loss : 0.5202381610870361\n",
            "Batch : 636, Loss : 0.4756472110748291\n",
            "Batch : 637, Loss : 0.393508642911911\n",
            "Batch : 638, Loss : 0.4570567309856415\n",
            "Batch : 639, Loss : 0.4211634695529938\n",
            "Batch : 640, Loss : 0.6245951056480408\n",
            "Batch : 641, Loss : 0.37790679931640625\n",
            "Batch : 642, Loss : 0.4805363416671753\n",
            "Batch : 643, Loss : 0.6612103581428528\n",
            "Batch : 644, Loss : 0.4727341830730438\n",
            "Batch : 645, Loss : 0.47224557399749756\n",
            "Batch : 646, Loss : 0.39518484473228455\n",
            "Batch : 647, Loss : 0.5734022259712219\n",
            "Batch : 648, Loss : 0.4464970827102661\n",
            "Batch : 649, Loss : 0.42848560214042664\n",
            "Batch : 650, Loss : 0.4576917290687561\n",
            "Batch : 651, Loss : 0.4936597943305969\n",
            "Batch : 652, Loss : 0.5095707774162292\n",
            "Batch : 653, Loss : 0.3352142870426178\n",
            "Batch : 654, Loss : 0.46876710653305054\n",
            "Batch : 655, Loss : 0.537612795829773\n",
            "Batch : 656, Loss : 0.4848349392414093\n",
            "Batch : 657, Loss : 0.581982433795929\n",
            "Batch : 658, Loss : 0.5679677128791809\n",
            "Batch : 659, Loss : 0.5387601852416992\n",
            "Batch : 660, Loss : 0.6889637112617493\n",
            "Batch : 661, Loss : 0.49170082807540894\n",
            "Batch : 662, Loss : 0.6493618488311768\n",
            "Batch : 663, Loss : 0.6532974243164062\n",
            "Batch : 664, Loss : 0.45480549335479736\n",
            "Batch : 665, Loss : 0.4818306267261505\n",
            "Batch : 666, Loss : 0.40194764733314514\n",
            "Batch : 667, Loss : 0.5308899879455566\n",
            "Batch : 668, Loss : 0.36601439118385315\n",
            "Batch : 669, Loss : 0.5690759420394897\n",
            "Batch : 670, Loss : 0.48892712593078613\n",
            "Batch : 671, Loss : 0.3106016516685486\n",
            "Batch : 672, Loss : 0.46991896629333496\n",
            "Batch : 673, Loss : 0.47076156735420227\n",
            "Batch : 674, Loss : 0.47324827313423157\n",
            "Batch : 675, Loss : 0.5896382927894592\n",
            "Batch : 676, Loss : 0.5460641384124756\n",
            "Batch : 677, Loss : 0.6804093718528748\n",
            "Batch : 678, Loss : 0.514334499835968\n",
            "Batch : 679, Loss : 0.41502806544303894\n",
            "Batch : 680, Loss : 0.4376222789287567\n",
            "Batch : 681, Loss : 0.4907977283000946\n",
            "Batch : 682, Loss : 0.43327879905700684\n",
            "Batch : 683, Loss : 0.44863560795783997\n",
            "Batch : 684, Loss : 0.5312294960021973\n",
            "Batch : 685, Loss : 0.3790968954563141\n",
            "Batch : 686, Loss : 0.45641911029815674\n",
            "Batch : 687, Loss : 0.47081834077835083\n",
            "Batch : 688, Loss : 0.5201957821846008\n",
            "Batch : 689, Loss : 0.5553209781646729\n",
            "Batch : 690, Loss : 0.4462742507457733\n",
            "Batch : 691, Loss : 0.6144301295280457\n",
            "Batch : 692, Loss : 0.3923545479774475\n",
            "Batch : 693, Loss : 0.5352843403816223\n",
            "Batch : 694, Loss : 0.5229499936103821\n",
            "Batch : 695, Loss : 0.5825629830360413\n",
            "Batch : 696, Loss : 0.5862520337104797\n",
            "Batch : 697, Loss : 0.5466163158416748\n",
            "Batch : 698, Loss : 0.38065531849861145\n",
            "Batch : 699, Loss : 0.5464386940002441\n",
            "Batch : 700, Loss : 0.6068993806838989\n",
            "Batch : 701, Loss : 0.6476452946662903\n",
            "Batch : 702, Loss : 0.44227224588394165\n",
            "Batch : 703, Loss : 0.3723139762878418\n",
            "Batch : 704, Loss : 0.3532165586948395\n",
            "Batch : 705, Loss : 0.49156609177589417\n",
            "Batch : 706, Loss : 0.5890331864356995\n",
            "Batch : 707, Loss : 0.34453344345092773\n",
            "Batch : 708, Loss : 0.549157440662384\n",
            "Batch : 709, Loss : 0.4830384850502014\n",
            "Batch : 710, Loss : 0.6666865348815918\n",
            "Batch : 711, Loss : 0.5080253481864929\n",
            "Batch : 712, Loss : 0.6130493879318237\n",
            "Batch : 713, Loss : 0.3145039677619934\n",
            "Batch : 714, Loss : 0.5401601195335388\n",
            "Batch : 715, Loss : 0.6791308522224426\n",
            "Batch : 716, Loss : 0.7512028813362122\n",
            "Batch : 717, Loss : 0.6546617746353149\n",
            "Batch : 718, Loss : 0.4040312170982361\n",
            "Batch : 719, Loss : 0.538004994392395\n",
            "Batch : 720, Loss : 0.4055294096469879\n",
            "Batch : 721, Loss : 0.46818119287490845\n",
            "Batch : 722, Loss : 0.47286364436149597\n",
            "Batch : 723, Loss : 0.42549511790275574\n",
            "Batch : 724, Loss : 0.6422604322433472\n",
            "Batch : 725, Loss : 0.5672923922538757\n",
            "Batch : 726, Loss : 0.5669445395469666\n",
            "Batch : 727, Loss : 0.4513903856277466\n",
            "Batch : 728, Loss : 0.36718034744262695\n",
            "Batch : 729, Loss : 0.42812851071357727\n",
            "Batch : 730, Loss : 0.7106680870056152\n",
            "Batch : 731, Loss : 0.449832558631897\n",
            "Batch : 732, Loss : 0.4780922830104828\n",
            "Batch : 733, Loss : 0.4386378228664398\n",
            "Batch : 734, Loss : 0.5049470067024231\n",
            "Batch : 735, Loss : 0.3754957318305969\n",
            "Batch : 736, Loss : 0.34432655572891235\n",
            "Batch : 737, Loss : 0.41191378235816956\n",
            "Batch : 738, Loss : 0.5835689306259155\n",
            "Batch : 739, Loss : 0.3691720962524414\n",
            "Batch : 740, Loss : 0.39733177423477173\n",
            "Batch : 741, Loss : 0.8959115743637085\n",
            "Batch : 742, Loss : 0.33089035749435425\n",
            "Batch : 743, Loss : 0.37508776783943176\n",
            "Batch : 744, Loss : 0.5375490784645081\n",
            "Batch : 745, Loss : 0.39384448528289795\n",
            "Batch : 746, Loss : 0.35150468349456787\n",
            "Batch : 747, Loss : 0.46034911274909973\n",
            "Batch : 748, Loss : 0.5066056847572327\n",
            "Batch : 749, Loss : 0.5972316265106201\n",
            "Batch : 750, Loss : 0.30488383769989014\n",
            "Batch : 751, Loss : 0.37790024280548096\n",
            "Batch : 752, Loss : 0.29856327176094055\n",
            "Batch : 753, Loss : 0.23697340488433838\n",
            "Batch : 754, Loss : 0.4908745586872101\n",
            "Batch : 755, Loss : 0.30373257398605347\n",
            "Batch : 756, Loss : 0.3225540816783905\n",
            "Batch : 757, Loss : 0.3277761936187744\n",
            "Batch : 758, Loss : 0.373115211725235\n",
            "Batch : 759, Loss : 0.5174171328544617\n",
            "Batch : 760, Loss : 0.663314938545227\n",
            "Batch : 761, Loss : 0.454196959733963\n",
            "Batch : 762, Loss : 0.6058206558227539\n",
            "Batch : 763, Loss : 0.6220178008079529\n",
            "Batch : 764, Loss : 0.3690722584724426\n",
            "Batch : 765, Loss : 0.48935049772262573\n",
            "Batch : 766, Loss : 0.6116330027580261\n",
            "Batch : 767, Loss : 0.4550744295120239\n",
            "Batch : 768, Loss : 0.43225452303886414\n",
            "Batch : 769, Loss : 0.3828389346599579\n",
            "Batch : 770, Loss : 0.6688938140869141\n",
            "Batch : 771, Loss : 0.3062770664691925\n",
            "Batch : 772, Loss : 0.389305055141449\n",
            "Batch : 773, Loss : 0.5057392716407776\n",
            "Batch : 774, Loss : 0.4434767961502075\n",
            "Batch : 775, Loss : 0.44802552461624146\n",
            "Batch : 776, Loss : 0.4933977425098419\n",
            "Batch : 777, Loss : 0.40724077820777893\n",
            "Batch : 778, Loss : 0.48092079162597656\n",
            "Batch : 779, Loss : 0.40992140769958496\n",
            "Batch : 780, Loss : 0.5832030773162842\n",
            "Batch : 781, Loss : 0.6129522919654846\n",
            "Batch : 782, Loss : 0.3439336121082306\n",
            "Batch : 783, Loss : 0.5939334630966187\n",
            "Batch : 784, Loss : 0.4096444249153137\n",
            "Batch : 785, Loss : 0.4170930087566376\n",
            "Batch : 786, Loss : 0.3279862403869629\n",
            "Batch : 787, Loss : 0.35106614232063293\n",
            "Batch : 788, Loss : 0.47550103068351746\n",
            "Batch : 789, Loss : 0.5302122831344604\n",
            "Batch : 790, Loss : 0.5063709020614624\n",
            "Batch : 791, Loss : 0.4868943691253662\n",
            "Batch : 792, Loss : 0.3954482674598694\n",
            "Batch : 793, Loss : 0.4373380243778229\n",
            "Batch : 794, Loss : 0.31366944313049316\n",
            "Batch : 795, Loss : 0.4641437530517578\n",
            "Batch : 796, Loss : 0.5710187554359436\n",
            "Batch : 797, Loss : 0.6601948142051697\n",
            "Batch : 798, Loss : 0.5379109382629395\n",
            "Batch : 799, Loss : 0.5115867853164673\n",
            "Batch : 800, Loss : 0.5305799245834351\n",
            "Batch : 801, Loss : 0.616234302520752\n",
            "Batch : 802, Loss : 0.4843207001686096\n",
            "Batch : 803, Loss : 0.5337091088294983\n",
            "Batch : 804, Loss : 0.4063970148563385\n",
            "Batch : 805, Loss : 0.4589310586452484\n",
            "Batch : 806, Loss : 0.5116112232208252\n",
            "Batch : 807, Loss : 0.5908227562904358\n",
            "Batch : 808, Loss : 0.48642823100090027\n",
            "Batch : 809, Loss : 0.4243559241294861\n",
            "Batch : 810, Loss : 0.5172827839851379\n",
            "Batch : 811, Loss : 0.6723011136054993\n",
            "Batch : 812, Loss : 0.561087429523468\n",
            "Batch : 813, Loss : 0.580245852470398\n",
            "Batch : 814, Loss : 0.4053511321544647\n",
            "Batch : 815, Loss : 0.586021900177002\n",
            "Batch : 816, Loss : 0.3894241452217102\n",
            "Batch : 817, Loss : 0.33964797854423523\n",
            "Batch : 818, Loss : 0.47431543469429016\n",
            "Batch : 819, Loss : 0.41238710284233093\n",
            "Batch : 820, Loss : 0.4737832844257355\n",
            "Batch : 821, Loss : 0.4449990391731262\n",
            "Batch : 822, Loss : 0.6274120807647705\n",
            "Batch : 823, Loss : 0.44708123803138733\n",
            "Batch : 824, Loss : 0.3499385118484497\n",
            "Batch : 825, Loss : 0.3782154619693756\n",
            "Batch : 826, Loss : 0.6202696561813354\n",
            "Batch : 827, Loss : 0.5457445383071899\n",
            "Batch : 828, Loss : 0.6542729735374451\n",
            "Batch : 829, Loss : 0.4351979196071625\n",
            "Batch : 830, Loss : 0.47354647517204285\n",
            "Batch : 831, Loss : 0.6806545853614807\n",
            "Batch : 832, Loss : 0.47151660919189453\n",
            "Batch : 833, Loss : 0.4868955612182617\n",
            "Batch : 834, Loss : 0.7441595792770386\n",
            "Batch : 835, Loss : 0.4919087886810303\n",
            "Batch : 836, Loss : 0.6010308265686035\n",
            "Batch : 837, Loss : 0.3505503833293915\n",
            "Batch : 838, Loss : 0.5340185165405273\n",
            "Batch : 839, Loss : 0.4238482117652893\n",
            "Batch : 840, Loss : 0.490069717168808\n",
            "Batch : 841, Loss : 0.5144747495651245\n",
            "Batch : 842, Loss : 0.5213284492492676\n",
            "Batch : 843, Loss : 0.5182925462722778\n",
            "Batch : 844, Loss : 0.47171851992607117\n",
            "Batch : 845, Loss : 0.43954840302467346\n",
            "Batch : 846, Loss : 0.4228004813194275\n",
            "Batch : 847, Loss : 0.4650837182998657\n",
            "Batch : 848, Loss : 0.5335759520530701\n",
            "Batch : 849, Loss : 0.433533638715744\n",
            "Batch : 850, Loss : 0.37334123253822327\n",
            "Batch : 851, Loss : 0.49789896607398987\n",
            "Batch : 852, Loss : 0.42289048433303833\n",
            "Batch : 853, Loss : 0.3559834659099579\n",
            "Batch : 854, Loss : 0.4045024514198303\n",
            "Batch : 855, Loss : 0.43523314595222473\n",
            "Batch : 856, Loss : 0.42140093445777893\n",
            "Batch : 857, Loss : 0.45785772800445557\n",
            "Batch : 858, Loss : 0.3749226927757263\n",
            "Batch : 859, Loss : 0.34969982504844666\n",
            "Batch : 860, Loss : 0.473380982875824\n",
            "Batch : 861, Loss : 0.48918890953063965\n",
            "Batch : 862, Loss : 0.6048192977905273\n",
            "Batch : 863, Loss : 0.5187610387802124\n",
            "Batch : 864, Loss : 0.614327073097229\n",
            "Batch : 865, Loss : 0.6167610883712769\n",
            "Batch : 866, Loss : 0.4235289990901947\n",
            "Batch : 867, Loss : 0.5725693702697754\n",
            "Batch : 868, Loss : 0.43584421277046204\n",
            "Batch : 869, Loss : 0.6590225696563721\n",
            "Batch : 870, Loss : 0.4108406603336334\n",
            "Batch : 871, Loss : 0.5558373332023621\n",
            "Batch : 872, Loss : 0.4183485209941864\n",
            "Batch : 873, Loss : 0.6766643524169922\n",
            "Batch : 874, Loss : 0.5404736995697021\n",
            "Batch : 875, Loss : 0.6207833290100098\n",
            "Batch : 876, Loss : 0.4494783878326416\n",
            "Batch : 877, Loss : 0.518298864364624\n",
            "Batch : 878, Loss : 0.49295926094055176\n",
            "Batch : 879, Loss : 0.4750634431838989\n",
            "Batch : 880, Loss : 0.3770030438899994\n",
            "Batch : 881, Loss : 0.42107924818992615\n",
            "Batch : 882, Loss : 0.5170928239822388\n",
            "Batch : 883, Loss : 0.45254871249198914\n",
            "Batch : 884, Loss : 0.31737369298934937\n",
            "Batch : 885, Loss : 0.4506491720676422\n",
            "Batch : 886, Loss : 0.4943426847457886\n",
            "Batch : 887, Loss : 0.594036877155304\n",
            "Batch : 888, Loss : 0.47180914878845215\n",
            "Batch : 889, Loss : 0.4049453139305115\n",
            "Batch : 890, Loss : 0.2836592495441437\n",
            "Batch : 891, Loss : 0.40139320492744446\n",
            "Batch : 892, Loss : 0.4753391146659851\n",
            "Batch : 893, Loss : 0.49426501989364624\n",
            "Batch : 894, Loss : 0.40657708048820496\n",
            "Batch : 895, Loss : 0.3394778370857239\n",
            "Batch : 896, Loss : 0.5141012072563171\n",
            "Batch : 897, Loss : 0.40736186504364014\n",
            "Batch : 898, Loss : 0.44925180077552795\n",
            "Batch : 899, Loss : 0.6528962850570679\n",
            "Batch : 900, Loss : 0.43744218349456787\n",
            "Batch : 901, Loss : 0.45954304933547974\n",
            "Batch : 902, Loss : 0.4665728509426117\n",
            "Batch : 903, Loss : 0.45572564005851746\n",
            "Batch : 904, Loss : 0.40754806995391846\n",
            "Batch : 905, Loss : 0.3633260428905487\n",
            "Batch : 906, Loss : 0.4746819734573364\n",
            "Batch : 907, Loss : 0.34886834025382996\n",
            "Batch : 908, Loss : 0.32889923453330994\n",
            "Batch : 909, Loss : 0.3627057671546936\n",
            "Batch : 910, Loss : 0.48314031958580017\n",
            "Batch : 911, Loss : 0.366627037525177\n",
            "Batch : 912, Loss : 0.5884000658988953\n",
            "Batch : 913, Loss : 0.4408666789531708\n",
            "Batch : 914, Loss : 0.47854337096214294\n",
            "Batch : 915, Loss : 0.31217828392982483\n",
            "Batch : 916, Loss : 0.43956631422042847\n",
            "Batch : 917, Loss : 0.3286758065223694\n",
            "Batch : 918, Loss : 0.6546328663825989\n",
            "Batch : 919, Loss : 0.6149365901947021\n",
            "Batch : 920, Loss : 0.44678062200546265\n",
            "Batch : 921, Loss : 0.3487052917480469\n",
            "Batch : 922, Loss : 0.34148845076560974\n",
            "Batch : 923, Loss : 0.30224189162254333\n",
            "Batch : 924, Loss : 0.44782692193984985\n",
            "Batch : 925, Loss : 0.38469958305358887\n",
            "Batch : 926, Loss : 0.4861339032649994\n",
            "Batch : 927, Loss : 0.4132855534553528\n",
            "Batch : 928, Loss : 0.6067906022071838\n",
            "Batch : 929, Loss : 0.4685696065425873\n",
            "Batch : 930, Loss : 0.4533657133579254\n",
            "Batch : 931, Loss : 0.5345427989959717\n",
            "Batch : 932, Loss : 0.6067008376121521\n",
            "Batch : 933, Loss : 0.5164737701416016\n",
            "Batch : 934, Loss : 0.24385039508342743\n",
            "Batch : 935, Loss : 0.4516124427318573\n",
            "Batch : 936, Loss : 0.6608062386512756\n",
            "Batch : 937, Loss : 0.4971478283405304\n",
            "Batch : 938, Loss : 0.21369671821594238\n",
            "Training loss: 0.4902729557108269\n"
          ]
        }
      ]
    }
  ]
}